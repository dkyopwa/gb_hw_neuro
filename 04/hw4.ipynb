{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hometask 4"
      ],
      "metadata": {
        "id": "yShH7LMJGYkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание:\n",
        "\n",
        "1. Попробовать улучшить точность распознования образов cifar 10 сверточной нейронной сетью, рассмотренной на уроке. Приложить анализ с описанием того, что улучшает работу нейронной сети и что ухудшает.\n",
        "1. Описать также в анализе какие необоходимо внести изменения в получившуюся у вас нейронную сеть если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET."
      ],
      "metadata": {
        "id": "RXBAKV5UGcKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "# установка параметров нейросети\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 1\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# разделение тренировочной и тестовой выборки\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'тренировочные примеры')\n",
        "print(x_test.shape[0], 'тестовые примеры')\n",
        "\n",
        "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Tfb2GbiaBuDj",
        "outputId": "bf47d1eb-c071-4fd4-9279-72ff86187fff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 тренировочные примеры\n",
            "10000 тестовые примеры\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JckPLMRRAFY7",
        "outputId": "f698cfb7-84dd-44aa-a0dd-276bd155c2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 тренировочные примеры\n",
            "10000 тестовые примеры\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Использование data augmentation в реальном времени\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e8cffeb38a1a>:127: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(x_train, y_train,\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1871: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 63s 34ms/step - loss: 1.8567 - accuracy: 0.3145 - val_loss: 2.1652 - val_accuracy: 0.1706\n",
            "сохранить обученную модель как /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.1652 - accuracy: 0.1706\n",
            "Test loss: 2.1652255058288574\n",
            "Test accuracy: 0.17059999704360962\n"
          ]
        }
      ],
      "source": [
        "# конфигурирование слоев нейросети\n",
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# инициализация RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Не используется data augmentation')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Использование data augmentation в реальном времени')\n",
        "    # Препроцессинг и data augmentation в реальном времени:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0., \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "  # Препроцессинг и data augmentation в реальном времени:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center= True,\n",
        "        samplewise_center=True,\n",
        "        featurewise_std_normalization=True,\n",
        "        samplewise_std_normalization=True,\n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0., \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # запуск data augmentation через fit\n",
        "    #datagen.fit(x_train)\n",
        "\n",
        "    # запуск data augmentation через fit_generator\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# сохранение модели и весов\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('сохранить обученную модель как %s ' % model_path)\n",
        "\n",
        "# проверка работы обученной модели\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Функция, которая создает модель\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # слои нейросети отвественные за свертку и max-pooling\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                     input_shape=x_train.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # полносвязные слои нейронной сети\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # инициализация RMSprop optimizer\n",
        "    opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "    # компиляция модели\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# создаем экземпляр модели для использования с Grid Search\n",
        "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# определяем параметры, которые будут оптимизироваться\n",
        "batch_size = [32, 64, 128]\n",
        "epochs = [10, 20]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# запускаем Grid Search\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
        "# grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "grid_result = dict()\n",
        "\n",
        "for bs in batch_size:\n",
        "    for ep in epochs:\n",
        "        model = create_model()\n",
        "        model.fit(x_train, y_train,\n",
        "              batch_size=bs,\n",
        "              epochs=ep,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "        scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "        grid_result[scores[1]] = {'accuracy':scores[1], 'loss':scores[0],\n",
        "                                  'batch_size':bs, 'epochs':ep}\n",
        "        print(grid_result[scores[1]])\n",
        "\n",
        "# выводим результаты\n",
        "key_min = list(grid_result.keys())\n",
        "key_min.sort(reverse=True)\n",
        "print(\"Лучший результат: %f с использованием %s\" % (key_min[0], grid_result[key_min[0]]))\n",
        "# тоже самое можно провернуть и с другими параметрами (кол-во слоев сети, размер фильтра и тд)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PJVPgnvrAL4J",
        "outputId": "eba86642-4c09-4b5b-fe55-0cfbd815e072"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 2.5815 - accuracy: 0.2969 - val_loss: 1.5437 - val_accuracy: 0.4486\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5219 - accuracy: 0.4461 - val_loss: 1.4361 - val_accuracy: 0.4948\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3672 - accuracy: 0.5111 - val_loss: 1.2160 - val_accuracy: 0.5728\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2598 - accuracy: 0.5534 - val_loss: 1.1552 - val_accuracy: 0.5942\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1835 - accuracy: 0.5845 - val_loss: 1.0563 - val_accuracy: 0.6296\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1313 - accuracy: 0.6027 - val_loss: 1.0881 - val_accuracy: 0.6219\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0850 - accuracy: 0.6230 - val_loss: 0.9765 - val_accuracy: 0.6621\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0501 - accuracy: 0.6364 - val_loss: 0.9462 - val_accuracy: 0.6741\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0210 - accuracy: 0.6465 - val_loss: 0.9978 - val_accuracy: 0.6581\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0070 - accuracy: 0.6522 - val_loss: 0.9404 - val_accuracy: 0.6803\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9404 - accuracy: 0.6803\n",
            "{'accuracy': 0.6802999973297119, 'loss': 0.9404318332672119, 'batch_size': 32, 'epochs': 10}\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 11s 6ms/step - loss: 2.4052 - accuracy: 0.3196 - val_loss: 1.4677 - val_accuracy: 0.4727\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4866 - accuracy: 0.4648 - val_loss: 1.3555 - val_accuracy: 0.5146\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3555 - accuracy: 0.5178 - val_loss: 1.2073 - val_accuracy: 0.5746\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2696 - accuracy: 0.5556 - val_loss: 1.1302 - val_accuracy: 0.6057\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2001 - accuracy: 0.5801 - val_loss: 1.0636 - val_accuracy: 0.6295\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1568 - accuracy: 0.5974 - val_loss: 1.0477 - val_accuracy: 0.6411\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1176 - accuracy: 0.6119 - val_loss: 1.0226 - val_accuracy: 0.6402\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0837 - accuracy: 0.6246 - val_loss: 1.0303 - val_accuracy: 0.6394\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0623 - accuracy: 0.6335 - val_loss: 0.9648 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0326 - accuracy: 0.6456 - val_loss: 0.9361 - val_accuracy: 0.6754\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0160 - accuracy: 0.6526 - val_loss: 0.9377 - val_accuracy: 0.6804\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0073 - accuracy: 0.6555 - val_loss: 1.0103 - val_accuracy: 0.6590\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9947 - accuracy: 0.6620 - val_loss: 0.9781 - val_accuracy: 0.6690\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9885 - accuracy: 0.6653 - val_loss: 0.9290 - val_accuracy: 0.6893\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9830 - accuracy: 0.6668 - val_loss: 0.9130 - val_accuracy: 0.6967\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9755 - accuracy: 0.6698 - val_loss: 0.9549 - val_accuracy: 0.6834\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9653 - accuracy: 0.6756 - val_loss: 0.9503 - val_accuracy: 0.6818\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9660 - accuracy: 0.6737 - val_loss: 0.9733 - val_accuracy: 0.6779\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9542 - accuracy: 0.6782 - val_loss: 0.8800 - val_accuracy: 0.7090\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9507 - accuracy: 0.6790 - val_loss: 0.9971 - val_accuracy: 0.6884\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9971 - accuracy: 0.6884\n",
            "{'accuracy': 0.6883999705314636, 'loss': 0.9970947504043579, 'batch_size': 32, 'epochs': 20}\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 2.8453 - accuracy: 0.2708 - val_loss: 1.6775 - val_accuracy: 0.4042\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6287 - accuracy: 0.4092 - val_loss: 1.4446 - val_accuracy: 0.4874\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.4830 - accuracy: 0.4661 - val_loss: 1.3292 - val_accuracy: 0.5329\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3826 - accuracy: 0.5068 - val_loss: 1.4292 - val_accuracy: 0.4820\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2992 - accuracy: 0.5357 - val_loss: 1.2436 - val_accuracy: 0.5651\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2340 - accuracy: 0.5638 - val_loss: 1.3139 - val_accuracy: 0.5350\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1895 - accuracy: 0.5789 - val_loss: 1.1691 - val_accuracy: 0.5888\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1379 - accuracy: 0.5997 - val_loss: 1.3576 - val_accuracy: 0.5474\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1042 - accuracy: 0.6131 - val_loss: 1.2316 - val_accuracy: 0.5687\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0740 - accuracy: 0.6249 - val_loss: 1.0079 - val_accuracy: 0.6511\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0079 - accuracy: 0.6511\n",
            "{'accuracy': 0.6510999798774719, 'loss': 1.007934331893921, 'batch_size': 64, 'epochs': 10}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 2.4494 - accuracy: 0.2815 - val_loss: 1.5602 - val_accuracy: 0.4475\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5870 - accuracy: 0.4257 - val_loss: 1.3976 - val_accuracy: 0.5030\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4352 - accuracy: 0.4844 - val_loss: 1.5479 - val_accuracy: 0.4706\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3428 - accuracy: 0.5221 - val_loss: 1.3155 - val_accuracy: 0.5450\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.2578 - accuracy: 0.5529 - val_loss: 1.1478 - val_accuracy: 0.5919\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1991 - accuracy: 0.5793 - val_loss: 1.1064 - val_accuracy: 0.6185\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1489 - accuracy: 0.5989 - val_loss: 1.0949 - val_accuracy: 0.6264\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1004 - accuracy: 0.6123 - val_loss: 1.0392 - val_accuracy: 0.6410\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0637 - accuracy: 0.6290 - val_loss: 1.0225 - val_accuracy: 0.6435\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0318 - accuracy: 0.6410 - val_loss: 1.0431 - val_accuracy: 0.6369\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0015 - accuracy: 0.6508 - val_loss: 0.9330 - val_accuracy: 0.6746\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9750 - accuracy: 0.6594 - val_loss: 1.0862 - val_accuracy: 0.6328\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9524 - accuracy: 0.6720 - val_loss: 0.9136 - val_accuracy: 0.6797\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9339 - accuracy: 0.6779 - val_loss: 0.8902 - val_accuracy: 0.6985\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9197 - accuracy: 0.6832 - val_loss: 0.9407 - val_accuracy: 0.6751\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9006 - accuracy: 0.6905 - val_loss: 0.8506 - val_accuracy: 0.7059\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8866 - accuracy: 0.6975 - val_loss: 0.8552 - val_accuracy: 0.7073\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8715 - accuracy: 0.7018 - val_loss: 0.8866 - val_accuracy: 0.6971\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8650 - accuracy: 0.6999 - val_loss: 0.8706 - val_accuracy: 0.7032\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8505 - accuracy: 0.7097 - val_loss: 0.8313 - val_accuracy: 0.7225\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8313 - accuracy: 0.7225\n",
            "{'accuracy': 0.7225000262260437, 'loss': 0.8313353657722473, 'batch_size': 64, 'epochs': 20}\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 7s 14ms/step - loss: 4.4031 - accuracy: 0.1670 - val_loss: 1.9353 - val_accuracy: 0.3089\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.8668 - accuracy: 0.3100 - val_loss: 1.5983 - val_accuracy: 0.4227\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.6342 - accuracy: 0.4067 - val_loss: 1.4430 - val_accuracy: 0.4840\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.5021 - accuracy: 0.4559 - val_loss: 1.3408 - val_accuracy: 0.5190\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.4174 - accuracy: 0.4895 - val_loss: 1.3233 - val_accuracy: 0.5258\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.3411 - accuracy: 0.5204 - val_loss: 1.2275 - val_accuracy: 0.5640\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2816 - accuracy: 0.5448 - val_loss: 1.2440 - val_accuracy: 0.5599\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2256 - accuracy: 0.5636 - val_loss: 1.1606 - val_accuracy: 0.5832\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1657 - accuracy: 0.5862 - val_loss: 1.1636 - val_accuracy: 0.5883\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1257 - accuracy: 0.6027 - val_loss: 1.0463 - val_accuracy: 0.6331\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0463 - accuracy: 0.6331\n",
            "{'accuracy': 0.6330999732017517, 'loss': 1.0463075637817383, 'batch_size': 128, 'epochs': 10}\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 6s 13ms/step - loss: 3.8262 - accuracy: 0.2273 - val_loss: 1.6936 - val_accuracy: 0.3964\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.7201 - accuracy: 0.3698 - val_loss: 1.5190 - val_accuracy: 0.4512\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.5578 - accuracy: 0.4355 - val_loss: 1.4156 - val_accuracy: 0.5061\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.4590 - accuracy: 0.4746 - val_loss: 1.3340 - val_accuracy: 0.5260\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.3919 - accuracy: 0.5027 - val_loss: 1.2638 - val_accuracy: 0.5522\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.3286 - accuracy: 0.5275 - val_loss: 1.2282 - val_accuracy: 0.5656\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2770 - accuracy: 0.5464 - val_loss: 1.1756 - val_accuracy: 0.5890\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2360 - accuracy: 0.5611 - val_loss: 1.1567 - val_accuracy: 0.6007\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1934 - accuracy: 0.5797 - val_loss: 1.0878 - val_accuracy: 0.6168\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1559 - accuracy: 0.5918 - val_loss: 1.0988 - val_accuracy: 0.6081\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1256 - accuracy: 0.6042 - val_loss: 1.0420 - val_accuracy: 0.6350\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0957 - accuracy: 0.6177 - val_loss: 1.0253 - val_accuracy: 0.6397\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0686 - accuracy: 0.6246 - val_loss: 1.0365 - val_accuracy: 0.6417\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0399 - accuracy: 0.6363 - val_loss: 0.9800 - val_accuracy: 0.6565\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0156 - accuracy: 0.6460 - val_loss: 0.9887 - val_accuracy: 0.6504\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9938 - accuracy: 0.6527 - val_loss: 0.9853 - val_accuracy: 0.6522\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9737 - accuracy: 0.6577 - val_loss: 0.9319 - val_accuracy: 0.6780\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9554 - accuracy: 0.6661 - val_loss: 0.9003 - val_accuracy: 0.6848\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9341 - accuracy: 0.6747 - val_loss: 0.9542 - val_accuracy: 0.6663\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9198 - accuracy: 0.6785 - val_loss: 0.8887 - val_accuracy: 0.6930\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8887 - accuracy: 0.6930\n",
            "{'accuracy': 0.6930000185966492, 'loss': 0.8887442350387573, 'batch_size': 128, 'epochs': 20}\n",
            "Лучший результат: 0.722500 с использованием {'accuracy': 0.7225000262260437, 'loss': 0.8313353657722473, 'batch_size': 64, 'epochs': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
        "\n",
        "  super().__init__(name, **kwargs)\n",
        "\n",
        "Epoch 1/10\n",
        "\n",
        "1563/1563 [==============================] - 11s 7ms/step - loss: 2.5815 - accuracy: 0.2969 - val_loss: 1.5437 - val_accuracy: 0.4486\n",
        "\n",
        "Epoch 2/10\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5219 - accuracy: 0.4461 - val_loss: 1.4361 - val_accuracy: 0.4948\n",
        "\n",
        "Epoch 3/10\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3672 - accuracy: 0.5111 - val_loss: 1.2160 - val_accuracy: 0.5728\n",
        "\n",
        "Epoch 4/10\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2598 - accuracy: 0.5534 - val_loss: 1.1552 - val_accuracy: 0.5942\n",
        "\n",
        "Epoch 5/10\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1835 - accuracy: 0.5845 - val_loss: 1.0563 - val_accuracy: 0.6296\n",
        "\n",
        "Epoch 6/10\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1313 - accuracy: 0.6027 - val_loss: 1.0881 - val_accuracy: 0.6219\n",
        "\n",
        "Epoch 7/10\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0850 - accuracy: 0.6230 - val_loss: 0.9765 - val_accuracy: 0.6621\n",
        "\n",
        "Epoch 8/10\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0501 - accuracy: 0.6364 - val_loss: 0.9462 - val_accuracy: 0.6741\n",
        "\n",
        "Epoch 9/10\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0210 - accuracy: 0.6465 - val_loss: 0.9978 - val_accuracy: 0.6581\n",
        "\n",
        "Epoch 10/10\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0070 - accuracy: 0.6522 - val_loss: 0.9404 - val_accuracy: 0.6803\n",
        "\n",
        "313/313 [==============================] - 1s 3ms/step - loss: 0.9404 - accuracy: 0.6803\n",
        "\n",
        "{'accuracy': 0.6802999973297119, 'loss': 0.9404318332672119, 'batch_size': 32, 'epochs': 10}\n",
        "\n",
        "Epoch 1/20\n",
        "\n",
        "1563/1563 [==============================] - 11s 6ms/step - loss: 2.4052 - accuracy: 0.3196 - val_loss: 1.4677 - val_accuracy: 0.4727\n",
        "\n",
        "Epoch 2/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4866 - accuracy: 0.4648 - val_loss: 1.3555 - val_accuracy: 0.5146\n",
        "\n",
        "Epoch 3/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3555 - accuracy: 0.5178 - val_loss: 1.2073 - val_accuracy: 0.5746\n",
        "\n",
        "Epoch 4/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2696 - accuracy: 0.5556 - val_loss: 1.1302 - val_accuracy: 0.6057\n",
        "\n",
        "Epoch 5/20\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2001 - accuracy: 0.5801 - val_loss: 1.0636 - val_accuracy: 0.6295\n",
        "\n",
        "Epoch 6/20\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1568 - accuracy: 0.5974 - val_loss: 1.0477 - val_accuracy: 0.6411\n",
        "\n",
        "Epoch 7/20\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1176 - accuracy: 0.6119 - val_loss: 1.0226 - val_accuracy: 0.6402\n",
        "\n",
        "Epoch 8/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0837 - accuracy: 0.6246 - val_loss: 1.0303 - val_accuracy: 0.6394\n",
        "\n",
        "Epoch 9/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0623 - accuracy: 0.6335 - val_loss: 0.9648 - val_accuracy: 0.6667\n",
        "\n",
        "Epoch 10/20\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0326 - accuracy: 0.6456 - val_loss: 0.9361 - val_accuracy: 0.6754\n",
        "\n",
        "Epoch 11/20\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0160 - accuracy: 0.6526 - val_loss: 0.9377 - val_accuracy: 0.6804\n",
        "\n",
        "Epoch 12/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0073 - accuracy: 0.6555 - val_loss: 1.0103 - val_accuracy: 0.6590\n",
        "\n",
        "Epoch 13/20\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9947 - accuracy: 0.6620 - val_loss: 0.9781 - val_accuracy: 0.6690\n",
        "\n",
        "Epoch 14/20\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9885 - accuracy: 0.6653 - val_loss: 0.9290 - val_accuracy: 0.6893\n",
        "\n",
        "Epoch 15/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9830 - accuracy: 0.6668 - val_loss: 0.9130 - val_accuracy: 0.6967\n",
        "\n",
        "Epoch 16/20\n",
        "\n",
        "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9755 - accuracy: 0.6698 - val_loss: 0.9549 - val_accuracy: 0.6834\n",
        "\n",
        "Epoch 17/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9653 - accuracy: 0.6756 - val_loss: 0.9503 - val_accuracy: 0.6818\n",
        "\n",
        "Epoch 18/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9660 - accuracy: 0.6737 - val_loss: 0.9733 - val_accuracy: 0.6779\n",
        "\n",
        "Epoch 19/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9542 - accuracy: 0.6782 - val_loss: 0.8800 - val_accuracy: 0.7090\n",
        "\n",
        "Epoch 20/20\n",
        "\n",
        "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9507 - accuracy: 0.6790 - val_loss: 0.9971 - val_accuracy: 0.6884\n",
        "\n",
        "313/313 [==============================] - 1s 3ms/step - loss: 0.9971 - accuracy: 0.6884\n",
        "\n",
        "{'accuracy': 0.6883999705314636, 'loss': 0.9970947504043579, 'batch_size': 32, 'epochs': 20}\n",
        "\n",
        "Epoch 1/10\n",
        "\n",
        "782/782 [==============================] - 8s 9ms/step - loss: 2.8453 - accuracy: 0.2708 - val_loss: 1.6775 - val_accuracy: 0.4042\n",
        "\n",
        "Epoch 2/10\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.6287 - accuracy: 0.4092 - val_loss: 1.4446 - val_accuracy: 0.4874\n",
        "\n",
        "Epoch 3/10\n",
        "\n",
        "782/782 [==============================] - 7s 8ms/step - loss: 1.4830 - accuracy: 0.4661 - val_loss: 1.3292 - val_accuracy: 0.5329\n",
        "\n",
        "Epoch 4/10\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.3826 - accuracy: 0.5068 - val_loss: 1.4292 - val_accuracy: 0.4820\n",
        "\n",
        "Epoch 5/10\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.2992 - accuracy: 0.5357 - val_loss: 1.2436 - val_accuracy: 0.5651\n",
        "\n",
        "Epoch 6/10\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.2340 - accuracy: 0.5638 - val_loss: 1.3139 - val_accuracy: 0.5350\n",
        "\n",
        "Epoch 7/10\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.1895 - accuracy: 0.5789 - val_loss: 1.1691 - val_accuracy: 0.5888\n",
        "\n",
        "Epoch 8/10\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.1379 - accuracy: 0.5997 - val_loss: 1.3576 - val_accuracy: 0.5474\n",
        "\n",
        "Epoch 9/10\n",
        "\n",
        "782/782 [==============================] - 7s 9ms/step - loss: 1.1042 - accuracy: 0.6131 - val_loss: 1.2316 - val_accuracy: 0.5687\n",
        "\n",
        "Epoch 10/10\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.0740 - accuracy: 0.6249 - val_loss: 1.0079 - val_accuracy: 0.6511\n",
        "\n",
        "313/313 [==============================] - 1s 3ms/step - loss: 1.0079 - accuracy: 0.6511\n",
        "\n",
        "{'accuracy': 0.6510999798774719, 'loss': 1.007934331893921, 'batch_size': 64, 'epochs': 10}\n",
        "\n",
        "Epoch 1/20\n",
        "\n",
        "782/782 [==============================] - 8s 9ms/step - loss: 2.4494 - accuracy: 0.2815 - val_loss: 1.5602 - val_accuracy: 0.4475\n",
        "\n",
        "Epoch 2/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.5870 - accuracy: 0.4257 - val_loss: 1.3976 - val_accuracy: 0.5030\n",
        "\n",
        "Epoch 3/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.4352 - accuracy: 0.4844 - val_loss: 1.5479 - val_accuracy: 0.4706\n",
        "\n",
        "Epoch 4/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.3428 - accuracy: 0.5221 - val_loss: 1.3155 - val_accuracy: 0.5450\n",
        "\n",
        "Epoch 5/20\n",
        "\n",
        "782/782 [==============================] - 7s 9ms/step - loss: 1.2578 - accuracy: 0.5529 - val_loss: 1.1478 - val_accuracy: 0.5919\n",
        "\n",
        "Epoch 6/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.1991 - accuracy: 0.5793 - val_loss: 1.1064 - val_accuracy: 0.6185\n",
        "\n",
        "Epoch 7/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.1489 - accuracy: 0.5989 - val_loss: 1.0949 - val_accuracy: 0.6264\n",
        "\n",
        "Epoch 8/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.1004 - accuracy: 0.6123 - val_loss: 1.0392 - val_accuracy: 0.6410\n",
        "\n",
        "Epoch 9/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.0637 - accuracy: 0.6290 - val_loss: 1.0225 - val_accuracy: 0.6435\n",
        "\n",
        "Epoch 10/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.0318 - accuracy: 0.6410 - val_loss: 1.0431 - val_accuracy: 0.6369\n",
        "\n",
        "Epoch 11/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 1.0015 - accuracy: 0.6508 - val_loss: 0.9330 - val_accuracy: 0.6746\n",
        "\n",
        "Epoch 12/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 0.9750 - accuracy: 0.6594 - val_loss: 1.0862 - val_accuracy: 0.6328\n",
        "\n",
        "Epoch 13/20\n",
        "\n",
        "782/782 [==============================] - 7s 9ms/step - loss: 0.9524 - accuracy: 0.6720 - val_loss: 0.9136 - val_accuracy: 0.6797\n",
        "\n",
        "Epoch 14/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 0.9339 - accuracy: 0.6779 - val_loss: 0.8902 - val_accuracy: 0.6985\n",
        "\n",
        "Epoch 15/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 0.9197 - accuracy: 0.6832 - val_loss: 0.9407 - val_accuracy: 0.6751\n",
        "\n",
        "Epoch 16/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 0.9006 - accuracy: 0.6905 - val_loss: 0.8506 - val_accuracy: 0.7059\n",
        "\n",
        "Epoch 17/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 0.8866 - accuracy: 0.6975 - val_loss: 0.8552 - val_accuracy: 0.7073\n",
        "\n",
        "Epoch 18/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 0.8715 - accuracy: 0.7018 - val_loss: 0.8866 - val_accuracy: 0.6971\n",
        "\n",
        "Epoch 19/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 0.8650 - accuracy: 0.6999 - val_loss: 0.8706 - val_accuracy: 0.7032\n",
        "\n",
        "Epoch 20/20\n",
        "\n",
        "782/782 [==============================] - 6s 8ms/step - loss: 0.8505 - accuracy: 0.7097 - val_loss: 0.8313 - val_accuracy: 0.7225\n",
        "\n",
        "313/313 [==============================] - 1s 4ms/step - loss: 0.8313 - accuracy: 0.7225\n",
        "\n",
        "{'accuracy': 0.7225000262260437, 'loss': 0.8313353657722473, 'batch_size': 64, 'epochs': 20}\n",
        "\n",
        "Epoch 1/10\n",
        "\n",
        "391/391 [==============================] - 7s 14ms/step - loss: 4.4031 - accuracy: 0.1670 - val_loss: 1.9353 - val_accuracy: 0.3089\n",
        "\n",
        "Epoch 2/10\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.8668 - accuracy: 0.3100 - val_loss: 1.5983 - val_accuracy: 0.4227\n",
        "\n",
        "Epoch 3/10\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 1.6342 - accuracy: 0.4067 - val_loss: 1.4430 - val_accuracy: 0.4840\n",
        "\n",
        "Epoch 4/10\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.5021 - accuracy: 0.4559 - val_loss: 1.3408 - val_accuracy: 0.5190\n",
        "\n",
        "Epoch 5/10\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.4174 - accuracy: 0.4895 - val_loss: 1.3233 - val_accuracy: 0.5258\n",
        "\n",
        "Epoch 6/10\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 1.3411 - accuracy: 0.5204 - val_loss: 1.2275 - val_accuracy: 0.5640\n",
        "\n",
        "Epoch 7/10\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.2816 - accuracy: 0.5448 - val_loss: 1.2440 - val_accuracy: 0.5599\n",
        "\n",
        "Epoch 8/10\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 1.2256 - accuracy: 0.5636 - val_loss: 1.1606 - val_accuracy: 0.5832\n",
        "\n",
        "Epoch 9/10\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.1657 - accuracy: 0.5862 - val_loss: 1.1636 - val_accuracy: 0.5883\n",
        "\n",
        "Epoch 10/10\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.1257 - accuracy: 0.6027 - val_loss: 1.0463 - val_accuracy: 0.6331\n",
        "\n",
        "313/313 [==============================] - 1s 3ms/step - loss: 1.0463 - accuracy: 0.6331\n",
        "\n",
        "{'accuracy': 0.6330999732017517, 'loss': 1.0463075637817383, 'batch_size': 128, 'epochs': 10}\n",
        "\n",
        "Epoch 1/20\n",
        "\n",
        "391/391 [==============================] - 6s 13ms/step - loss: 3.8262 - accuracy: 0.2273 - val_loss: 1.6936 - val_accuracy: 0.3964\n",
        "\n",
        "Epoch 2/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.7201 - accuracy: 0.3698 - val_loss: 1.5190 - val_accuracy: 0.4512\n",
        "\n",
        "Epoch 3/20\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 1.5578 - accuracy: 0.4355 - val_loss: 1.4156 - val_accuracy: 0.5061\n",
        "\n",
        "Epoch 4/20\n",
        "\n",
        "391/391 [==============================] - 5s 14ms/step - loss: 1.4590 - accuracy: 0.4746 - val_loss: 1.3340 - val_accuracy: 0.5260\n",
        "\n",
        "Epoch 5/20\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 1.3919 - accuracy: 0.5027 - val_loss: 1.2638 - val_accuracy: 0.5522\n",
        "\n",
        "Epoch 6/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.3286 - accuracy: 0.5275 - val_loss: 1.2282 - val_accuracy: 0.5656\n",
        "\n",
        "Epoch 7/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.2770 - accuracy: 0.5464 - val_loss: 1.1756 - val_accuracy: 0.5890\n",
        "\n",
        "Epoch 8/20\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 1.2360 - accuracy: 0.5611 - val_loss: 1.1567 - val_accuracy: 0.6007\n",
        "\n",
        "Epoch 9/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.1934 - accuracy: 0.5797 - val_loss: 1.0878 - val_accuracy: 0.6168\n",
        "\n",
        "Epoch 10/20\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 1.1559 - accuracy: 0.5918 - val_loss: 1.0988 - val_accuracy: 0.6081\n",
        "\n",
        "Epoch 11/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.1256 - accuracy: 0.6042 - val_loss: 1.0420 - val_accuracy: 0.6350\n",
        "\n",
        "Epoch 12/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.0957 - accuracy: 0.6177 - val_loss: 1.0253 - val_accuracy: 0.6397\n",
        "\n",
        "Epoch 13/20\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 1.0686 - accuracy: 0.6246 - val_loss: 1.0365 - val_accuracy: 0.6417\n",
        "\n",
        "Epoch 14/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 1.0399 - accuracy: 0.6363 - val_loss: 0.9800 - val_accuracy: 0.6565\n",
        "\n",
        "Epoch 15/20\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 1.0156 - accuracy: 0.6460 - val_loss: 0.9887 - val_accuracy: 0.6504\n",
        "\n",
        "Epoch 16/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 0.9938 - accuracy: 0.6527 - val_loss: 0.9853 - val_accuracy: 0.6522\n",
        "\n",
        "Epoch 17/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 0.9737 - accuracy: 0.6577 - val_loss: 0.9319 - val_accuracy: 0.6780\n",
        "\n",
        "Epoch 18/20\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 0.9554 - accuracy: 0.6661 - val_loss: 0.9003 - val_accuracy: 0.6848\n",
        "\n",
        "Epoch 19/20\n",
        "\n",
        "391/391 [==============================] - 5s 13ms/step - loss: 0.9341 - accuracy: 0.6747 - val_loss: 0.9542 - val_accuracy: 0.6663\n",
        "\n",
        "Epoch 20/20\n",
        "\n",
        "391/391 [==============================] - 5s 12ms/step - loss: 0.9198 - accuracy: 0.6785 - val_loss: 0.8887 - val_accuracy: 0.6930\n",
        "\n",
        "313/313 [==============================] - 1s 3ms/step - loss: 0.8887 - accuracy: 0.6930\n",
        "\n",
        "{'accuracy': 0.6930000185966492, 'loss': 0.8887442350387573, 'batch_size': 128, 'epochs': 20}\n",
        "\n",
        "Лучший результат: 0.722500 с использованием {'accuracy': 0.7225000262260437, 'loss': 0.8313353657722473, 'batch_size': 64, 'epochs': 20}"
      ],
      "metadata": {
        "id": "0jfI9CgYFVw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Улучшение"
      ],
      "metadata": {
        "id": "LmFeeH9NHYHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем более глубокую сеть (за счёт уменьшения смещения окна)."
      ],
      "metadata": {
        "id": "V12tc4YxJbNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                  input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gxO82bWQHjSU",
        "outputId": "210ff901-69d2-42f3-ddbb-15382dbfeda2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_62 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_90 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " activation_91 (Activation)  (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 29, 29, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 29, 29, 32)        0         \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " activation_92 (Activation)  (None, 29, 29, 64)        0         \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 27, 27, 64)        36928     \n",
            "                                                                 \n",
            " activation_93 (Activation)  (None, 27, 27, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 26, 26, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 26, 26, 64)        0         \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 26, 26, 64)        36928     \n",
            "                                                                 \n",
            " activation_94 (Activation)  (None, 26, 26, 64)        0         \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 24, 24, 64)        36928     \n",
            "                                                                 \n",
            " activation_95 (Activation)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 12, 12, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1024)              9438208   \n",
            "                                                                 \n",
            " activation_96 (Activation)  (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            " activation_97 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,587,882\n",
            "Trainable params: 9,587,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция, которая создает модель\n",
        "def create_model(opt=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)):\n",
        "    model = Sequential()\n",
        "\n",
        "    # слои нейросети отвественные за свертку и max-pooling\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                      input_shape=x_train.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # полносвязные слои нейронной сети\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # инициализация RMSprop optimizer\n",
        "    opt = opt\n",
        "\n",
        "    # компиляция модели\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# создаем экземпляр модели для использования с Grid Search\n",
        "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# определяем параметры, которые будут оптимизироваться\n",
        "opts = [keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "        keras.optimizers.Adam(learning_rate=0.001),\n",
        "        keras.optimizers.Adamax(learning_rate=0.001)]\n",
        "\n",
        "# запускаем Grid Search\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
        "# grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "grid_result = dict()\n",
        "\n",
        "for opt in opts:\n",
        "    model = create_model(opt=opt)\n",
        "    model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          epochs=20,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n",
        "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "    grid_result[scores[1]] = {'accuracy':scores[1], 'loss':scores[0],\n",
        "                              'opt':opt}\n",
        "    print(grid_result[scores[1]])\n",
        "\n",
        "# выводим результаты\n",
        "key_min = list(grid_result.keys())\n",
        "key_min.sort(reverse=True)\n",
        "print(\"Лучший результат: %f с использованием %s\" % (key_min[0], grid_result[key_min[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K8XdqK96FW60",
        "outputId": "2839bc90-0ab9-41bd-a3c1-48650ee209c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 21s 25ms/step - loss: 2.5612 - accuracy: 0.2524 - val_loss: 1.5685 - val_accuracy: 0.4297\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.4187 - accuracy: 0.4999 - val_loss: 1.3149 - val_accuracy: 0.5377\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.2609 - accuracy: 0.5602 - val_loss: 1.4268 - val_accuracy: 0.4948\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.2045 - accuracy: 0.5805 - val_loss: 1.4438 - val_accuracy: 0.4935\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1645 - accuracy: 0.5966 - val_loss: 1.1935 - val_accuracy: 0.5865\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1350 - accuracy: 0.6103 - val_loss: 1.2270 - val_accuracy: 0.5743\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 19s 25ms/step - loss: 1.1203 - accuracy: 0.6148 - val_loss: 1.1247 - val_accuracy: 0.6215\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 19s 25ms/step - loss: 1.1164 - accuracy: 0.6207 - val_loss: 1.1298 - val_accuracy: 0.6062\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 19s 25ms/step - loss: 1.1057 - accuracy: 0.6198 - val_loss: 1.2308 - val_accuracy: 0.5913\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1170 - accuracy: 0.6199 - val_loss: 1.0668 - val_accuracy: 0.6282\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.0999 - accuracy: 0.6248 - val_loss: 1.1784 - val_accuracy: 0.5966\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1008 - accuracy: 0.6293 - val_loss: 1.2267 - val_accuracy: 0.5818\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1154 - accuracy: 0.6249 - val_loss: 1.0556 - val_accuracy: 0.6349\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1005 - accuracy: 0.6275 - val_loss: 1.1990 - val_accuracy: 0.5962\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1097 - accuracy: 0.6269 - val_loss: 1.0169 - val_accuracy: 0.6507\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1115 - accuracy: 0.6257 - val_loss: 0.9792 - val_accuracy: 0.6624\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1234 - accuracy: 0.6194 - val_loss: 1.1633 - val_accuracy: 0.5993\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1226 - accuracy: 0.6216 - val_loss: 1.1818 - val_accuracy: 0.5993\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1190 - accuracy: 0.6256 - val_loss: 1.0810 - val_accuracy: 0.6302\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1129 - accuracy: 0.6267 - val_loss: 1.1354 - val_accuracy: 0.6338\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1354 - accuracy: 0.6338\n",
            "{'accuracy': 0.6338000297546387, 'loss': 1.1353555917739868, 'opt': <keras.optimizers.legacy.rmsprop.RMSprop object at 0x7fc8bc0550a0>}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.8289 - accuracy: 0.1014 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3030 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3031 - accuracy: 0.0977 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3029 - accuracy: 0.0985 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3030 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3162 - accuracy: 0.1004 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3031 - accuracy: 0.0989 - val_loss: 2.3029 - val_accuracy: 0.0999\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 2.3031 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3029 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 18s 22ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3029 - accuracy: 0.0970 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.5541 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3029 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3028 - accuracy: 0.0963 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.1000\n",
            "{'accuracy': 0.10000000149011612, 'loss': 2.3025944232940674, 'opt': <keras.optimizers.legacy.adam.Adam object at 0x7fc8bc055070>}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 19s 23ms/step - loss: 2.3167 - accuracy: 0.2442 - val_loss: 1.6212 - val_accuracy: 0.4139\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 1.5008 - accuracy: 0.4516 - val_loss: 1.3582 - val_accuracy: 0.5246\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.2810 - accuracy: 0.5427 - val_loss: 1.2283 - val_accuracy: 0.5584\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 1.1272 - accuracy: 0.6028 - val_loss: 1.0713 - val_accuracy: 0.6261\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 1.0152 - accuracy: 0.6443 - val_loss: 0.9799 - val_accuracy: 0.6587\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.9180 - accuracy: 0.6801 - val_loss: 0.8932 - val_accuracy: 0.6984\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.8284 - accuracy: 0.7111 - val_loss: 0.8346 - val_accuracy: 0.7095\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.7374 - accuracy: 0.7420 - val_loss: 0.7674 - val_accuracy: 0.7346\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.6649 - accuracy: 0.7680 - val_loss: 0.8187 - val_accuracy: 0.7174\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.5994 - accuracy: 0.7916 - val_loss: 0.7237 - val_accuracy: 0.7504\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.5299 - accuracy: 0.8146 - val_loss: 0.7321 - val_accuracy: 0.7550\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.4748 - accuracy: 0.8340 - val_loss: 0.7182 - val_accuracy: 0.7677\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.4274 - accuracy: 0.8504 - val_loss: 0.7654 - val_accuracy: 0.7583\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.3823 - accuracy: 0.8676 - val_loss: 0.7286 - val_accuracy: 0.7715\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.3404 - accuracy: 0.8806 - val_loss: 0.7532 - val_accuracy: 0.7705\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.3098 - accuracy: 0.8911 - val_loss: 0.7493 - val_accuracy: 0.7668\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.2815 - accuracy: 0.9018 - val_loss: 0.8007 - val_accuracy: 0.7722\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2534 - accuracy: 0.9115 - val_loss: 0.8442 - val_accuracy: 0.7642\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.2337 - accuracy: 0.9185 - val_loss: 0.8187 - val_accuracy: 0.7743\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2188 - accuracy: 0.9246 - val_loss: 0.7745 - val_accuracy: 0.7814\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.7745 - accuracy: 0.7814\n",
            "{'accuracy': 0.7814000248908997, 'loss': 0.7745427489280701, 'opt': <keras.optimizers.legacy.adamax.Adamax object at 0x7fc8bc055f40>}\n",
            "Лучший результат: 0.781400 с использованием {'accuracy': 0.7814000248908997, 'loss': 0.7745427489280701, 'opt': <keras.optimizers.legacy.adamax.Adamax object at 0x7fc8bc055f40>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Победителем является опмитизацтор Adamax. Ниже скопированы результаты, чтобы не потерялись при переносе в случае чего.\n",
        "\n",
        "Стоит отметить, что Adam показал наихудшие результаты и вообще не смог обучиться."
      ],
      "metadata": {
        "id": "0G9m_DlTYDOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 1/20\n",
        "\n",
        "782/782 [==============================] - 21s 25ms/step - loss: 2.5612 - accuracy: 0.2524 - val_loss: 1.5685 - val_accuracy: 0.4297\n",
        "\n",
        "Epoch 2/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.4187 - accuracy: 0.4999 - val_loss: 1.3149 - val_accuracy: 0.5377\n",
        "\n",
        "Epoch 3/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.2609 - accuracy: 0.5602 - val_loss: 1.4268 - val_accuracy: 0.4948\n",
        "\n",
        "Epoch 4/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.2045 - accuracy: 0.5805 - val_loss: 1.4438 - val_accuracy: 0.4935\n",
        "\n",
        "Epoch 5/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1645 - accuracy: 0.5966 - val_loss: 1.1935 - val_accuracy: 0.5865\n",
        "\n",
        "Epoch 6/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1350 - accuracy: 0.6103 - val_loss: 1.2270 - val_accuracy: 0.5743\n",
        "\n",
        "Epoch 7/20\n",
        "\n",
        "782/782 [==============================] - 19s 25ms/step - loss: 1.1203 - accuracy: 0.6148 - val_loss: 1.1247 - val_accuracy: 0.6215\n",
        "\n",
        "Epoch 8/20\n",
        "\n",
        "782/782 [==============================] - 19s 25ms/step - loss: 1.1164 - accuracy: 0.6207 - val_loss: 1.1298 - val_accuracy: 0.6062\n",
        "\n",
        "Epoch 9/20\n",
        "\n",
        "782/782 [==============================] - 19s 25ms/step - loss: 1.1057 - accuracy: 0.6198 - val_loss: 1.2308 - val_accuracy: 0.5913\n",
        "\n",
        "Epoch 10/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1170 - accuracy: 0.6199 - val_loss: 1.0668 - val_accuracy: 0.6282\n",
        "\n",
        "Epoch 11/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.0999 - accuracy: 0.6248 - val_loss: 1.1784 - val_accuracy: 0.5966\n",
        "\n",
        "Epoch 12/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1008 - accuracy: 0.6293 - val_loss: 1.2267 - val_accuracy: 0.5818\n",
        "\n",
        "Epoch 13/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1154 - accuracy: 0.6249 - val_loss: 1.0556 - val_accuracy: 0.6349\n",
        "\n",
        "Epoch 14/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1005 - accuracy: 0.6275 - val_loss: 1.1990 - val_accuracy: 0.5962\n",
        "\n",
        "Epoch 15/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1097 - accuracy: 0.6269 - val_loss: 1.0169 - val_accuracy: 0.6507\n",
        "\n",
        "Epoch 16/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1115 - accuracy: 0.6257 - val_loss: 0.9792 - val_accuracy: 0.6624\n",
        "\n",
        "Epoch 17/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1234 - accuracy: 0.6194 - val_loss: 1.1633 - val_accuracy: 0.5993\n",
        "\n",
        "Epoch 18/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1226 - accuracy: 0.6216 - val_loss: 1.1818 - val_accuracy: 0.5993\n",
        "\n",
        "Epoch 19/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1190 - accuracy: 0.6256 - val_loss: 1.0810 - val_accuracy: 0.6302\n",
        "\n",
        "Epoch 20/20\n",
        "\n",
        "782/782 [==============================] - 19s 24ms/step - loss: 1.1129 - accuracy: 0.6267 - val_loss: 1.1354 - val_accuracy: 0.6338\n",
        "\n",
        "313/313 [==============================] - 2s 6ms/step - loss: 1.1354 - accuracy: 0.6338\n",
        "\n",
        "{'accuracy': 0.6338000297546387, 'loss': 1.1353555917739868, 'opt': <keras.optimizers.legacy.rmsprop.RMSprop object at 0x7fc8bc0550a0>}\n",
        "\n",
        "Epoch 1/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 2.8289 - accuracy: 0.1014 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
        "\n",
        "Epoch 2/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3030 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 3/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3031 - accuracy: 0.0977 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 4/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3029 - accuracy: 0.0985 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 5/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3030 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 6/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3162 - accuracy: 0.1004 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 7/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3031 - accuracy: 0.0989 - val_loss: 2.3029 - val_accuracy: 0.0999\n",
        "\n",
        "Epoch 8/20\n",
        "\n",
        "782/782 [==============================] - 17s 21ms/step - loss: 2.3031 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 9/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3029 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 10/20\n",
        "\n",
        "782/782 [==============================] - 18s 22ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 11/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3029 - accuracy: 0.0970 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 12/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.5541 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 13/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3029 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 14/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3028 - accuracy: 0.0963 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 15/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 16/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 17/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 18/20\n",
        "\n",
        "782/782 [==============================] - 17s 21ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 19/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "Epoch 20/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
        "\n",
        "313/313 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.1000\n",
        "\n",
        "{'accuracy': 0.10000000149011612, 'loss': 2.3025944232940674, 'opt': <keras.optimizers.legacy.adam.Adam object at 0x7fc8bc055070>}\n",
        "\n",
        "Epoch 1/20\n",
        "\n",
        "782/782 [==============================] - 19s 23ms/step - loss: 2.3167 - accuracy: 0.2442 - val_loss: 1.6212 - val_accuracy: 0.4139\n",
        "\n",
        "Epoch 2/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 1.5008 - accuracy: 0.4516 - val_loss: 1.3582 - val_accuracy: 0.5246\n",
        "\n",
        "Epoch 3/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 1.2810 - accuracy: 0.5427 - val_loss: 1.2283 - val_accuracy: 0.5584\n",
        "\n",
        "Epoch 4/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 1.1272 - accuracy: 0.6028 - val_loss: 1.0713 - val_accuracy: 0.6261\n",
        "\n",
        "Epoch 5/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 1.0152 - accuracy: 0.6443 - val_loss: 0.9799 - val_accuracy: 0.6587\n",
        "\n",
        "Epoch 6/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.9180 - accuracy: 0.6801 - val_loss: 0.8932 - val_accuracy: 0.6984\n",
        "\n",
        "Epoch 7/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.8284 - accuracy: 0.7111 - val_loss: 0.8346 - val_accuracy: 0.7095\n",
        "\n",
        "Epoch 8/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 0.7374 - accuracy: 0.7420 - val_loss: 0.7674 - val_accuracy: 0.7346\n",
        "\n",
        "Epoch 9/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.6649 - accuracy: 0.7680 - val_loss: 0.8187 - val_accuracy: 0.7174\n",
        "\n",
        "Epoch 10/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 0.5994 - accuracy: 0.7916 - val_loss: 0.7237 - val_accuracy: 0.7504\n",
        "\n",
        "Epoch 11/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.5299 - accuracy: 0.8146 - val_loss: 0.7321 - val_accuracy: 0.7550\n",
        "\n",
        "Epoch 12/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.4748 - accuracy: 0.8340 - val_loss: 0.7182 - val_accuracy: 0.7677\n",
        "\n",
        "Epoch 13/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.4274 - accuracy: 0.8504 - val_loss: 0.7654 - val_accuracy: 0.7583\n",
        "\n",
        "Epoch 14/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.3823 - accuracy: 0.8676 - val_loss: 0.7286 - val_accuracy: 0.7715\n",
        "\n",
        "Epoch 15/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.3404 - accuracy: 0.8806 - val_loss: 0.7532 - val_accuracy: 0.7705\n",
        "\n",
        "Epoch 16/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.3098 - accuracy: 0.8911 - val_loss: 0.7493 - val_accuracy: 0.7668\n",
        "\n",
        "Epoch 17/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.2815 - accuracy: 0.9018 - val_loss: 0.8007 - val_accuracy: 0.7722\n",
        "\n",
        "Epoch 18/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 0.2534 - accuracy: 0.9115 - val_loss: 0.8442 - val_accuracy: 0.7642\n",
        "\n",
        "Epoch 19/20\n",
        "\n",
        "782/782 [==============================] - 18s 23ms/step - loss: 0.2337 - accuracy: 0.9185 - val_loss: 0.8187 - val_accuracy: 0.7743\n",
        "\n",
        "Epoch 20/20\n",
        "\n",
        "782/782 [==============================] - 17s 22ms/step - loss: 0.2188 - accuracy: 0.9246 - val_loss: 0.7745 - val_accuracy: 0.7814\n",
        "\n",
        "313/313 [==============================] - 1s 4ms/step - loss: 0.7745 - accuracy: 0.7814\n",
        "\n",
        "{'accuracy': 0.7814000248908997, 'loss': 0.7745427489280701, 'opt': <keras.optimizers.legacy.adamax.Adamax object at 0x7fc8bc055f40>}\n",
        "\n",
        "Лучший результат: 0.781400 с использованием {'accuracy': 0.7814000248908997, 'loss': 0.7745427489280701, 'opt': <keras.optimizers.legacy.adamax.Adamax object at 0x7fc8bc055f40>}"
      ],
      "metadata": {
        "id": "of78CCUbQ1FA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем оставить такую же глубокую сеть, только в слое пулинга сделаем большее окно. Это несного уменьшит сеть и чуть быстрее будет обучение. Проанализируем результаты, чтобы понять, как этого окно пулинга влияет."
      ],
      "metadata": {
        "id": "M6z-WGtBYh6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                  input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IwBK5vWFQ2FN",
        "outputId": "1b6bd08e-ac30-44c1-fd42-8d337ec5967e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_86 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_122 (Activation)  (None, 32, 32, 32)       0         \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " activation_123 (Activation)  (None, 30, 30, 32)       0         \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPoolin  (None, 28, 28, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_88 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " activation_124 (Activation)  (None, 28, 28, 64)       0         \n",
            "                                                                 \n",
            " conv2d_89 (Conv2D)          (None, 26, 26, 64)        36928     \n",
            "                                                                 \n",
            " activation_125 (Activation)  (None, 26, 26, 64)       0         \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPoolin  (None, 24, 24, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2d_90 (Conv2D)          (None, 24, 24, 64)        36928     \n",
            "                                                                 \n",
            " activation_126 (Activation)  (None, 24, 24, 64)       0         \n",
            "                                                                 \n",
            " conv2d_91 (Conv2D)          (None, 22, 22, 64)        36928     \n",
            "                                                                 \n",
            " activation_127 (Activation)  (None, 22, 22, 64)       0         \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 10, 10, 64)        0         \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 1024)              6554624   \n",
            "                                                                 \n",
            " activation_128 (Activation)  (None, 1024)             0         \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            " activation_129 (Activation)  (None, 10)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,704,298\n",
            "Trainable params: 6,704,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция, которая создает модель\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # слои нейросети отвественные за свертку и max-pooling\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                      input_shape=x_train.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # полносвязные слои нейронной сети\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # инициализация RMSprop optimizer\n",
        "    opt = keras.optimizers.Adamax(learning_rate=0.001)\n",
        "\n",
        "    # компиляция модели\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# определяем параметры, которые будут оптимизироваться\n",
        "opts = []\n",
        "\n",
        "grid_result = dict()\n",
        "\n",
        "# for opt in opts:\n",
        "model = create_model()\n",
        "model.fit(x_train, y_train,\n",
        "      batch_size=64,\n",
        "      epochs=20,\n",
        "      validation_data=(x_test, y_test),\n",
        "      shuffle=True)\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "grid_result[scores[1]] = {'accuracy':scores[1], 'loss':scores[0]}\n",
        "print(grid_result[scores[1]])\n",
        "\n",
        "# выводим результаты\n",
        "key_min = list(grid_result.keys())\n",
        "key_min.sort(reverse=True)\n",
        "print(\"Лучший результат: %f с использованием %s\" % (key_min[0], grid_result[key_min[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JUkcnPXwWzqR",
        "outputId": "d90fad51-df16-462b-9a27-f144d99137b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 18s 21ms/step - loss: 2.1251 - accuracy: 0.3651 - val_loss: 1.5189 - val_accuracy: 0.4697\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.3842 - accuracy: 0.5008 - val_loss: 1.3584 - val_accuracy: 0.5306\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 1.2398 - accuracy: 0.5587 - val_loss: 1.1451 - val_accuracy: 0.6024\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 1.1211 - accuracy: 0.6058 - val_loss: 1.1807 - val_accuracy: 0.5701\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.0316 - accuracy: 0.6370 - val_loss: 1.0307 - val_accuracy: 0.6406\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.9283 - accuracy: 0.6786 - val_loss: 0.9002 - val_accuracy: 0.6974\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.8552 - accuracy: 0.7017 - val_loss: 0.8808 - val_accuracy: 0.6974\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.7851 - accuracy: 0.7267 - val_loss: 0.8124 - val_accuracy: 0.7232\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.7302 - accuracy: 0.7441 - val_loss: 0.7769 - val_accuracy: 0.7326\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6714 - accuracy: 0.7667 - val_loss: 0.7386 - val_accuracy: 0.7486\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.6316 - accuracy: 0.7792 - val_loss: 0.7427 - val_accuracy: 0.7504\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.5867 - accuracy: 0.7957 - val_loss: 0.7244 - val_accuracy: 0.7498\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.5457 - accuracy: 0.8089 - val_loss: 0.6967 - val_accuracy: 0.7657\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.5008 - accuracy: 0.8251 - val_loss: 0.6754 - val_accuracy: 0.7761\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 18s 22ms/step - loss: 0.4678 - accuracy: 0.8363 - val_loss: 0.6948 - val_accuracy: 0.7735\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.4438 - accuracy: 0.8433 - val_loss: 0.7311 - val_accuracy: 0.7651\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.4015 - accuracy: 0.8592 - val_loss: 0.7066 - val_accuracy: 0.7775\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.3810 - accuracy: 0.8654 - val_loss: 0.6847 - val_accuracy: 0.7808\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3538 - accuracy: 0.8755 - val_loss: 0.7153 - val_accuracy: 0.7729\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3322 - accuracy: 0.8831 - val_loss: 0.6966 - val_accuracy: 0.7862\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.6966 - accuracy: 0.7862\n",
            "{'accuracy': 0.7861999869346619, 'loss': 0.6966086626052856}\n",
            "Лучший результат: 0.786200 с использованием {'accuracy': 0.7861999869346619, 'loss': 0.6966086626052856}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На сколько видно, результаты те же, в пределах погрешности. Попробуем ещё раз, только с большим смещением окна."
      ],
      "metadata": {
        "id": "R2UnPzEkY865"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                  input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3QjxHfLyXVKL",
        "outputId": "d7c9fbcf-3f1a-4af3-fb55-fddda7da59a2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_98 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_138 (Activation)  (None, 32, 32, 32)       0         \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " activation_139 (Activation)  (None, 30, 30, 32)       0         \n",
            "                                                                 \n",
            " max_pooling2d_49 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " activation_140 (Activation)  (None, 14, 14, 64)       0         \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " activation_141 (Activation)  (None, 12, 12, 64)       0         \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 5, 5, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 5, 5, 64)          36928     \n",
            "                                                                 \n",
            " activation_142 (Activation)  (None, 5, 5, 64)         0         \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " activation_143 (Activation)  (None, 3, 3, 64)         0         \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 1, 1, 64)          0         \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 1024)              66560     \n",
            "                                                                 \n",
            " activation_144 (Activation)  (None, 1024)             0         \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            " activation_145 (Activation)  (None, 10)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 216,234\n",
            "Trainable params: 216,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Глубина сети осталась та же. А вот количество параметров обучения занчительно снизилось."
      ],
      "metadata": {
        "id": "G_rP15qJZZEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция, которая создает модель\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # слои нейросети отвественные за свертку и max-pooling\n",
        "    model = Sequential()\n",
        "\n",
        "    # слои нейросети отвественные за свертку и max-pooling\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                      input_shape=x_train.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # полносвязные слои нейронной сети\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # инициализация RMSprop optimizer\n",
        "    opt = keras.optimizers.Adamax(learning_rate=0.001)\n",
        "\n",
        "    # компиляция модели\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# определяем параметры, которые будут оптимизироваться\n",
        "opts = []\n",
        "\n",
        "grid_result = dict()\n",
        "\n",
        "# for opt in opts:\n",
        "model = create_model()\n",
        "model.fit(x_train, y_train,\n",
        "      batch_size=64,\n",
        "      epochs=20,\n",
        "      validation_data=(x_test, y_test),\n",
        "      shuffle=True)\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "grid_result[scores[1]] = {'accuracy':scores[1], 'loss':scores[0]}\n",
        "print(grid_result[scores[1]])\n",
        "\n",
        "# выводим результаты\n",
        "key_min = list(grid_result.keys())\n",
        "key_min.sort(reverse=True)\n",
        "print(\"Лучший результат: %f с использованием %s\" % (key_min[0], grid_result[key_min[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jixzjHx2ZKze",
        "outputId": "509a2e16-72c1-46f7-8a2d-9cc5aea9dfe6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 2.0044 - accuracy: 0.2461 - val_loss: 1.7024 - val_accuracy: 0.3658\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6202 - accuracy: 0.3895 - val_loss: 1.4493 - val_accuracy: 0.4722\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4435 - accuracy: 0.4713 - val_loss: 1.2782 - val_accuracy: 0.5398\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3185 - accuracy: 0.5281 - val_loss: 1.1864 - val_accuracy: 0.5782\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2269 - accuracy: 0.5623 - val_loss: 1.1028 - val_accuracy: 0.6106\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1451 - accuracy: 0.5941 - val_loss: 1.0376 - val_accuracy: 0.6413\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0728 - accuracy: 0.6240 - val_loss: 0.9945 - val_accuracy: 0.6594\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0227 - accuracy: 0.6432 - val_loss: 0.9417 - val_accuracy: 0.6800\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9663 - accuracy: 0.6624 - val_loss: 0.9035 - val_accuracy: 0.6948\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9209 - accuracy: 0.6787 - val_loss: 0.8441 - val_accuracy: 0.7172\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8930 - accuracy: 0.6902 - val_loss: 0.8306 - val_accuracy: 0.7182\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8568 - accuracy: 0.7035 - val_loss: 0.8135 - val_accuracy: 0.7248\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8311 - accuracy: 0.7139 - val_loss: 0.8035 - val_accuracy: 0.7286\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8029 - accuracy: 0.7252 - val_loss: 0.7608 - val_accuracy: 0.7423\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7804 - accuracy: 0.7318 - val_loss: 0.7394 - val_accuracy: 0.7526\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7586 - accuracy: 0.7402 - val_loss: 0.7318 - val_accuracy: 0.7566\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7418 - accuracy: 0.7415 - val_loss: 0.7266 - val_accuracy: 0.7550\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7183 - accuracy: 0.7542 - val_loss: 0.7045 - val_accuracy: 0.7656\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7040 - accuracy: 0.7592 - val_loss: 0.7164 - val_accuracy: 0.7575\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6956 - accuracy: 0.7627 - val_loss: 0.7294 - val_accuracy: 0.7515\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7294 - accuracy: 0.7515\n",
            "{'accuracy': 0.7515000104904175, 'loss': 0.7294091582298279}\n",
            "Лучший результат: 0.751500 с использованием {'accuracy': 0.7515000104904175, 'loss': 0.7294091582298279}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "216 тыс. параметров против 6,7 млн. - разница порядка 3%. Можно сослаться на статистическую погрешность. А за счёт более быстрого обучения добавить количество итераций и получить те же результаты.\n",
        "\n",
        "Для просторы обучения используем последний вариант.\n",
        "\n",
        "Сейчас можно подобрать параметры оптимизатора."
      ],
      "metadata": {
        "id": "Jcn0OTqgaCRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция, которая создает модель\n",
        "def create_model(learning_rate=0.001, epsilon=1e-07, ema_momentum=0.99):\n",
        "    model = Sequential()\n",
        "\n",
        "    # слои нейросети отвественные за свертку и max-pooling\n",
        "    model = Sequential()\n",
        "\n",
        "    # слои нейросети отвественные за свертку и max-pooling\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                      input_shape=x_train.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # полносвязные слои нейронной сети\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # инициализация RMSprop optimizer\n",
        "    opt = keras.optimizers.Adamax(learning_rate=0.001)\n",
        "\n",
        "    # компиляция модели\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# определяем параметры, которые будут оптимизироваться\n",
        "learning_rate = [0.01, 0.001, 0.0001]\n",
        "epsilon = [1e-06, 1e-07]\n",
        "ema_momentum = [0.99, 0.999]\n",
        "\n",
        "grid_result = dict()\n",
        "\n",
        "for lr in learning_rate:\n",
        "    for ep in epsilon:\n",
        "        for em in ema_momentum:\n",
        "            model = create_model(learning_rate=lr, epsilon=ep, ema_momentum=em)\n",
        "            model.fit(x_train, y_train,\n",
        "                  batch_size=64,\n",
        "                  epochs=20,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  shuffle=True)\n",
        "            scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "            grid_result[scores[1]] = {'accuracy':scores[1], 'loss':scores[0],\n",
        "                                      'learning_rate':lr, 'epsilon':ep,\n",
        "                                      'ema_momentum':em}\n",
        "            print(grid_result[scores[1]])\n",
        "\n",
        "# выводим результаты\n",
        "key_min = list(grid_result.keys())\n",
        "key_min.sort(reverse=True)\n",
        "print(\"Лучший результат: %f с использованием %s\" % (key_min[0], grid_result[key_min[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2FXN1e1NZf9x",
        "outputId": "03791284-9d5f-40ce-bb86-caac575cdd5e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 2.0254 - accuracy: 0.2317 - val_loss: 1.6790 - val_accuracy: 0.3544\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6304 - accuracy: 0.3854 - val_loss: 1.5203 - val_accuracy: 0.4475\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4410 - accuracy: 0.4758 - val_loss: 1.2737 - val_accuracy: 0.5502\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3020 - accuracy: 0.5347 - val_loss: 1.1531 - val_accuracy: 0.5947\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2045 - accuracy: 0.5738 - val_loss: 1.0828 - val_accuracy: 0.6219\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1294 - accuracy: 0.6029 - val_loss: 1.0029 - val_accuracy: 0.6491\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0616 - accuracy: 0.6277 - val_loss: 0.9741 - val_accuracy: 0.6591\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0191 - accuracy: 0.6441 - val_loss: 0.9363 - val_accuracy: 0.6746\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9671 - accuracy: 0.6644 - val_loss: 0.8827 - val_accuracy: 0.6952\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9323 - accuracy: 0.6737 - val_loss: 0.8729 - val_accuracy: 0.6957\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8948 - accuracy: 0.6884 - val_loss: 0.8539 - val_accuracy: 0.7023\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 0.8570 - accuracy: 0.7023 - val_loss: 0.7980 - val_accuracy: 0.7300\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8355 - accuracy: 0.7103 - val_loss: 0.8086 - val_accuracy: 0.7232\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8124 - accuracy: 0.7184 - val_loss: 0.7725 - val_accuracy: 0.7373\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7856 - accuracy: 0.7296 - val_loss: 0.7599 - val_accuracy: 0.7419\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7636 - accuracy: 0.7352 - val_loss: 0.7573 - val_accuracy: 0.7404\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7447 - accuracy: 0.7422 - val_loss: 0.7219 - val_accuracy: 0.7513\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7244 - accuracy: 0.7506 - val_loss: 0.7290 - val_accuracy: 0.7544\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7093 - accuracy: 0.7544 - val_loss: 0.7110 - val_accuracy: 0.7578\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6970 - accuracy: 0.7583 - val_loss: 0.6834 - val_accuracy: 0.7694\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6834 - accuracy: 0.7694\n",
            "{'accuracy': 0.7694000005722046, 'loss': 0.6833812594413757, 'learning_rate': 0.01, 'epsilon': 1e-06, 'ema_momentum': 0.99}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.9898 - accuracy: 0.2501 - val_loss: 1.6394 - val_accuracy: 0.3959\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5991 - accuracy: 0.4024 - val_loss: 1.5508 - val_accuracy: 0.4402\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4171 - accuracy: 0.4819 - val_loss: 1.2677 - val_accuracy: 0.5558\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2863 - accuracy: 0.5396 - val_loss: 1.1375 - val_accuracy: 0.5883\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1831 - accuracy: 0.5788 - val_loss: 1.1487 - val_accuracy: 0.5998\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1072 - accuracy: 0.6074 - val_loss: 0.9770 - val_accuracy: 0.6540\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0411 - accuracy: 0.6331 - val_loss: 0.9911 - val_accuracy: 0.6515\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9873 - accuracy: 0.6543 - val_loss: 0.8732 - val_accuracy: 0.6926\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9462 - accuracy: 0.6688 - val_loss: 0.8527 - val_accuracy: 0.7040\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8942 - accuracy: 0.6876 - val_loss: 0.8303 - val_accuracy: 0.7070\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8660 - accuracy: 0.7004 - val_loss: 0.8348 - val_accuracy: 0.7070\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8400 - accuracy: 0.7103 - val_loss: 0.8067 - val_accuracy: 0.7183\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8067 - accuracy: 0.7196 - val_loss: 0.7421 - val_accuracy: 0.7403\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7873 - accuracy: 0.7274 - val_loss: 0.7729 - val_accuracy: 0.7310\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7614 - accuracy: 0.7358 - val_loss: 0.7366 - val_accuracy: 0.7487\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7485 - accuracy: 0.7418 - val_loss: 0.7108 - val_accuracy: 0.7553\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7261 - accuracy: 0.7485 - val_loss: 0.7087 - val_accuracy: 0.7525\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7078 - accuracy: 0.7562 - val_loss: 0.7178 - val_accuracy: 0.7511\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7005 - accuracy: 0.7600 - val_loss: 0.6868 - val_accuracy: 0.7644\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6875 - accuracy: 0.7625 - val_loss: 0.6702 - val_accuracy: 0.7734\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6702 - accuracy: 0.7734\n",
            "{'accuracy': 0.7734000086784363, 'loss': 0.6701763272285461, 'learning_rate': 0.01, 'epsilon': 1e-06, 'ema_momentum': 0.999}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 2.0167 - accuracy: 0.2345 - val_loss: 1.6972 - val_accuracy: 0.3786\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6514 - accuracy: 0.3822 - val_loss: 1.4512 - val_accuracy: 0.4611\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4546 - accuracy: 0.4698 - val_loss: 1.3215 - val_accuracy: 0.5330\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3297 - accuracy: 0.5183 - val_loss: 1.1994 - val_accuracy: 0.5637\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2277 - accuracy: 0.5620 - val_loss: 1.2345 - val_accuracy: 0.5545\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1429 - accuracy: 0.5967 - val_loss: 1.0315 - val_accuracy: 0.6404\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0766 - accuracy: 0.6204 - val_loss: 0.9684 - val_accuracy: 0.6634\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.0173 - accuracy: 0.6438 - val_loss: 0.9252 - val_accuracy: 0.6804\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9681 - accuracy: 0.6637 - val_loss: 0.8838 - val_accuracy: 0.6963\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9217 - accuracy: 0.6783 - val_loss: 0.8822 - val_accuracy: 0.6955\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8898 - accuracy: 0.6934 - val_loss: 0.8097 - val_accuracy: 0.7232\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8502 - accuracy: 0.7040 - val_loss: 0.7859 - val_accuracy: 0.7331\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8291 - accuracy: 0.7128 - val_loss: 0.8364 - val_accuracy: 0.7111\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8032 - accuracy: 0.7203 - val_loss: 0.7763 - val_accuracy: 0.7390\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7789 - accuracy: 0.7317 - val_loss: 0.7464 - val_accuracy: 0.7484\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7616 - accuracy: 0.7352 - val_loss: 0.7100 - val_accuracy: 0.7604\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7447 - accuracy: 0.7432 - val_loss: 0.7303 - val_accuracy: 0.7551\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7221 - accuracy: 0.7522 - val_loss: 0.7144 - val_accuracy: 0.7590\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7112 - accuracy: 0.7561 - val_loss: 0.7223 - val_accuracy: 0.7559\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7011 - accuracy: 0.7581 - val_loss: 0.6834 - val_accuracy: 0.7707\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.6834 - accuracy: 0.7707\n",
            "{'accuracy': 0.7706999778747559, 'loss': 0.6833863258361816, 'learning_rate': 0.01, 'epsilon': 1e-07, 'ema_momentum': 0.99}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 8ms/step - loss: 2.1199 - accuracy: 0.1965 - val_loss: 1.7771 - val_accuracy: 0.3421\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 1.7268 - accuracy: 0.3388 - val_loss: 1.5775 - val_accuracy: 0.4226\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.5187 - accuracy: 0.4366 - val_loss: 1.3528 - val_accuracy: 0.5113\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.3652 - accuracy: 0.5090 - val_loss: 1.2203 - val_accuracy: 0.5676\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.2537 - accuracy: 0.5486 - val_loss: 1.1661 - val_accuracy: 0.5833\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1686 - accuracy: 0.5865 - val_loss: 1.0747 - val_accuracy: 0.6302\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0891 - accuracy: 0.6134 - val_loss: 1.0147 - val_accuracy: 0.6438\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0269 - accuracy: 0.6400 - val_loss: 0.9399 - val_accuracy: 0.6721\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.9715 - accuracy: 0.6588 - val_loss: 0.8931 - val_accuracy: 0.6920\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9296 - accuracy: 0.6776 - val_loss: 0.8861 - val_accuracy: 0.6976\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.9020 - accuracy: 0.6880 - val_loss: 0.8390 - val_accuracy: 0.7165\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8666 - accuracy: 0.7009 - val_loss: 0.8530 - val_accuracy: 0.7077\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8348 - accuracy: 0.7148 - val_loss: 0.8126 - val_accuracy: 0.7223\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8084 - accuracy: 0.7227 - val_loss: 0.7538 - val_accuracy: 0.7486\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7874 - accuracy: 0.7320 - val_loss: 0.7471 - val_accuracy: 0.7540\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7695 - accuracy: 0.7357 - val_loss: 0.7526 - val_accuracy: 0.7451\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7461 - accuracy: 0.7434 - val_loss: 0.7566 - val_accuracy: 0.7431\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7362 - accuracy: 0.7464 - val_loss: 0.7310 - val_accuracy: 0.7548\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7157 - accuracy: 0.7545 - val_loss: 0.6985 - val_accuracy: 0.7644\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7003 - accuracy: 0.7595 - val_loss: 0.7378 - val_accuracy: 0.7496\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.7378 - accuracy: 0.7496\n",
            "{'accuracy': 0.7495999932289124, 'loss': 0.7378082871437073, 'learning_rate': 0.01, 'epsilon': 1e-07, 'ema_momentum': 0.999}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 9s 10ms/step - loss: 2.0753 - accuracy: 0.2171 - val_loss: 1.7634 - val_accuracy: 0.3415\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.7134 - accuracy: 0.3468 - val_loss: 1.5024 - val_accuracy: 0.4443\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5030 - accuracy: 0.4421 - val_loss: 1.3140 - val_accuracy: 0.5178\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.3529 - accuracy: 0.5098 - val_loss: 1.1880 - val_accuracy: 0.5773\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.2299 - accuracy: 0.5587 - val_loss: 1.1122 - val_accuracy: 0.6084\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.1457 - accuracy: 0.5930 - val_loss: 1.0601 - val_accuracy: 0.6229\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.0756 - accuracy: 0.6208 - val_loss: 1.0132 - val_accuracy: 0.6451\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0236 - accuracy: 0.6390 - val_loss: 0.9457 - val_accuracy: 0.6769\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9721 - accuracy: 0.6558 - val_loss: 0.8888 - val_accuracy: 0.6917\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.9323 - accuracy: 0.6731 - val_loss: 0.8681 - val_accuracy: 0.7058\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8923 - accuracy: 0.6884 - val_loss: 0.8397 - val_accuracy: 0.7081\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8655 - accuracy: 0.6986 - val_loss: 0.8178 - val_accuracy: 0.7180\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 0.8373 - accuracy: 0.7095 - val_loss: 0.7911 - val_accuracy: 0.7308\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8074 - accuracy: 0.7189 - val_loss: 0.7810 - val_accuracy: 0.7293\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7858 - accuracy: 0.7258 - val_loss: 0.7477 - val_accuracy: 0.7444\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7699 - accuracy: 0.7336 - val_loss: 0.7621 - val_accuracy: 0.7393\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7442 - accuracy: 0.7436 - val_loss: 0.7376 - val_accuracy: 0.7476\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7329 - accuracy: 0.7449 - val_loss: 0.7362 - val_accuracy: 0.7517\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7110 - accuracy: 0.7540 - val_loss: 0.6925 - val_accuracy: 0.7645\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 0.7015 - accuracy: 0.7587 - val_loss: 0.6783 - val_accuracy: 0.7701\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6783 - accuracy: 0.7701\n",
            "{'accuracy': 0.7700999975204468, 'loss': 0.6783345341682434, 'learning_rate': 0.001, 'epsilon': 1e-06, 'ema_momentum': 0.99}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 2.0615 - accuracy: 0.2208 - val_loss: 1.7246 - val_accuracy: 0.3673\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.6523 - accuracy: 0.3828 - val_loss: 1.4568 - val_accuracy: 0.4703\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.4730 - accuracy: 0.4645 - val_loss: 1.3230 - val_accuracy: 0.5225\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.3385 - accuracy: 0.5182 - val_loss: 1.1630 - val_accuracy: 0.5842\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2428 - accuracy: 0.5574 - val_loss: 1.0983 - val_accuracy: 0.6090\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1545 - accuracy: 0.5901 - val_loss: 1.0501 - val_accuracy: 0.6277\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0895 - accuracy: 0.6140 - val_loss: 0.9711 - val_accuracy: 0.6631\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0352 - accuracy: 0.6363 - val_loss: 0.9299 - val_accuracy: 0.6734\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9906 - accuracy: 0.6533 - val_loss: 0.9128 - val_accuracy: 0.6866\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9413 - accuracy: 0.6709 - val_loss: 0.9689 - val_accuracy: 0.6629\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9051 - accuracy: 0.6825 - val_loss: 0.8178 - val_accuracy: 0.7156\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8712 - accuracy: 0.6992 - val_loss: 0.8419 - val_accuracy: 0.7092\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8495 - accuracy: 0.7033 - val_loss: 0.7994 - val_accuracy: 0.7282\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8164 - accuracy: 0.7165 - val_loss: 0.7676 - val_accuracy: 0.7325\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8037 - accuracy: 0.7220 - val_loss: 0.7590 - val_accuracy: 0.7370\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7730 - accuracy: 0.7325 - val_loss: 0.7361 - val_accuracy: 0.7485\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7606 - accuracy: 0.7368 - val_loss: 0.7387 - val_accuracy: 0.7464\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7370 - accuracy: 0.7452 - val_loss: 0.7156 - val_accuracy: 0.7549\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7176 - accuracy: 0.7521 - val_loss: 0.6992 - val_accuracy: 0.7601\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7083 - accuracy: 0.7550 - val_loss: 0.6880 - val_accuracy: 0.7628\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.6880 - accuracy: 0.7628\n",
            "{'accuracy': 0.7627999782562256, 'loss': 0.6879851818084717, 'learning_rate': 0.001, 'epsilon': 1e-06, 'ema_momentum': 0.999}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.9888 - accuracy: 0.2480 - val_loss: 1.6350 - val_accuracy: 0.3966\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.6145 - accuracy: 0.3969 - val_loss: 1.4837 - val_accuracy: 0.4655\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.4461 - accuracy: 0.4735 - val_loss: 1.3095 - val_accuracy: 0.5336\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.3229 - accuracy: 0.5250 - val_loss: 1.1969 - val_accuracy: 0.5653\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.2223 - accuracy: 0.5642 - val_loss: 1.1270 - val_accuracy: 0.6050\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1433 - accuracy: 0.5965 - val_loss: 1.0857 - val_accuracy: 0.6205\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0810 - accuracy: 0.6204 - val_loss: 0.9991 - val_accuracy: 0.6497\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 1.0232 - accuracy: 0.6389 - val_loss: 0.9488 - val_accuracy: 0.6729\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9780 - accuracy: 0.6591 - val_loss: 0.8848 - val_accuracy: 0.6938\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9376 - accuracy: 0.6714 - val_loss: 0.8779 - val_accuracy: 0.6941\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9034 - accuracy: 0.6848 - val_loss: 0.8513 - val_accuracy: 0.7075\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8720 - accuracy: 0.6939 - val_loss: 0.8152 - val_accuracy: 0.7169\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8418 - accuracy: 0.7083 - val_loss: 0.7983 - val_accuracy: 0.7190\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8110 - accuracy: 0.7196 - val_loss: 0.7563 - val_accuracy: 0.7362\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7999 - accuracy: 0.7233 - val_loss: 0.7793 - val_accuracy: 0.7365\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7733 - accuracy: 0.7329 - val_loss: 0.7434 - val_accuracy: 0.7433\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7529 - accuracy: 0.7397 - val_loss: 0.7229 - val_accuracy: 0.7523\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7390 - accuracy: 0.7452 - val_loss: 0.7265 - val_accuracy: 0.7533\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7156 - accuracy: 0.7544 - val_loss: 0.7239 - val_accuracy: 0.7514\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7033 - accuracy: 0.7582 - val_loss: 0.6960 - val_accuracy: 0.7659\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6960 - accuracy: 0.7659\n",
            "{'accuracy': 0.7659000158309937, 'loss': 0.6959818005561829, 'learning_rate': 0.001, 'epsilon': 1e-07, 'ema_momentum': 0.99}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.0021 - accuracy: 0.2406 - val_loss: 1.6779 - val_accuracy: 0.3907\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.6387 - accuracy: 0.3877 - val_loss: 1.4730 - val_accuracy: 0.4581\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.4576 - accuracy: 0.4735 - val_loss: 1.2788 - val_accuracy: 0.5484\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.3203 - accuracy: 0.5268 - val_loss: 1.2269 - val_accuracy: 0.5620\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.2259 - accuracy: 0.5630 - val_loss: 1.1028 - val_accuracy: 0.6115\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.1524 - accuracy: 0.5924 - val_loss: 1.0623 - val_accuracy: 0.6267\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.0767 - accuracy: 0.6216 - val_loss: 0.9728 - val_accuracy: 0.6616\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.0283 - accuracy: 0.6401 - val_loss: 0.9474 - val_accuracy: 0.6717\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.9876 - accuracy: 0.6561 - val_loss: 0.9201 - val_accuracy: 0.6844\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9286 - accuracy: 0.6724 - val_loss: 0.8530 - val_accuracy: 0.7049\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 0.9047 - accuracy: 0.6862 - val_loss: 0.8381 - val_accuracy: 0.7138\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8708 - accuracy: 0.6989 - val_loss: 0.8373 - val_accuracy: 0.7171\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8429 - accuracy: 0.7087 - val_loss: 0.8088 - val_accuracy: 0.7250\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8144 - accuracy: 0.7170 - val_loss: 0.7874 - val_accuracy: 0.7301\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7916 - accuracy: 0.7255 - val_loss: 0.7378 - val_accuracy: 0.7466\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7663 - accuracy: 0.7360 - val_loss: 0.7400 - val_accuracy: 0.7485\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7486 - accuracy: 0.7418 - val_loss: 0.7233 - val_accuracy: 0.7508\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7365 - accuracy: 0.7457 - val_loss: 0.7300 - val_accuracy: 0.7571\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7151 - accuracy: 0.7534 - val_loss: 0.6949 - val_accuracy: 0.7646\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7032 - accuracy: 0.7589 - val_loss: 0.7069 - val_accuracy: 0.7621\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.7069 - accuracy: 0.7621\n",
            "{'accuracy': 0.7620999813079834, 'loss': 0.7068541646003723, 'learning_rate': 0.001, 'epsilon': 1e-07, 'ema_momentum': 0.999}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 2.0087 - accuracy: 0.2395 - val_loss: 1.6921 - val_accuracy: 0.3836\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.6495 - accuracy: 0.3836 - val_loss: 1.4923 - val_accuracy: 0.4602\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.4705 - accuracy: 0.4609 - val_loss: 1.3515 - val_accuracy: 0.5217\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.3411 - accuracy: 0.5176 - val_loss: 1.2323 - val_accuracy: 0.5625\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.2207 - accuracy: 0.5665 - val_loss: 1.1011 - val_accuracy: 0.6118\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.1392 - accuracy: 0.5973 - val_loss: 1.0177 - val_accuracy: 0.6458\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0760 - accuracy: 0.6226 - val_loss: 0.9714 - val_accuracy: 0.6602\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 1.0170 - accuracy: 0.6436 - val_loss: 0.9300 - val_accuracy: 0.6785\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.9708 - accuracy: 0.6601 - val_loss: 0.8811 - val_accuracy: 0.6985\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9360 - accuracy: 0.6748 - val_loss: 0.8639 - val_accuracy: 0.7018\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8933 - accuracy: 0.6892 - val_loss: 0.8288 - val_accuracy: 0.7168\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8620 - accuracy: 0.7010 - val_loss: 0.8760 - val_accuracy: 0.6966\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8374 - accuracy: 0.7107 - val_loss: 0.7795 - val_accuracy: 0.7347\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8074 - accuracy: 0.7204 - val_loss: 0.7742 - val_accuracy: 0.7403\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7811 - accuracy: 0.7286 - val_loss: 0.7724 - val_accuracy: 0.7400\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7657 - accuracy: 0.7351 - val_loss: 0.7582 - val_accuracy: 0.7479\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7447 - accuracy: 0.7444 - val_loss: 0.7266 - val_accuracy: 0.7568\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7238 - accuracy: 0.7517 - val_loss: 0.7114 - val_accuracy: 0.7629\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7055 - accuracy: 0.7555 - val_loss: 0.7278 - val_accuracy: 0.7534\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.6881 - accuracy: 0.7616 - val_loss: 0.6906 - val_accuracy: 0.7678\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6906 - accuracy: 0.7678\n",
            "{'accuracy': 0.767799973487854, 'loss': 0.6905759572982788, 'learning_rate': 0.0001, 'epsilon': 1e-06, 'ema_momentum': 0.99}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.9884 - accuracy: 0.2469 - val_loss: 1.7189 - val_accuracy: 0.3798\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.6347 - accuracy: 0.3882 - val_loss: 1.4938 - val_accuracy: 0.4645\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4757 - accuracy: 0.4581 - val_loss: 1.3581 - val_accuracy: 0.5132\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.3536 - accuracy: 0.5098 - val_loss: 1.2352 - val_accuracy: 0.5601\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2498 - accuracy: 0.5562 - val_loss: 1.1586 - val_accuracy: 0.5924\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1786 - accuracy: 0.5830 - val_loss: 1.1473 - val_accuracy: 0.6010\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1111 - accuracy: 0.6125 - val_loss: 1.0144 - val_accuracy: 0.6559\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.0571 - accuracy: 0.6279 - val_loss: 0.9609 - val_accuracy: 0.6641\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0042 - accuracy: 0.6490 - val_loss: 0.9345 - val_accuracy: 0.6768\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.9610 - accuracy: 0.6662 - val_loss: 0.8865 - val_accuracy: 0.6911\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9244 - accuracy: 0.6779 - val_loss: 0.8622 - val_accuracy: 0.7058\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8858 - accuracy: 0.6917 - val_loss: 0.8129 - val_accuracy: 0.7236\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8531 - accuracy: 0.7044 - val_loss: 0.8396 - val_accuracy: 0.7046\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8276 - accuracy: 0.7143 - val_loss: 0.8114 - val_accuracy: 0.7172\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8047 - accuracy: 0.7220 - val_loss: 0.7809 - val_accuracy: 0.7336\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7786 - accuracy: 0.7327 - val_loss: 0.7665 - val_accuracy: 0.7390\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7622 - accuracy: 0.7367 - val_loss: 0.7389 - val_accuracy: 0.7498\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7430 - accuracy: 0.7426 - val_loss: 0.7202 - val_accuracy: 0.7559\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7257 - accuracy: 0.7498 - val_loss: 0.6895 - val_accuracy: 0.7646\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7022 - accuracy: 0.7587 - val_loss: 0.7094 - val_accuracy: 0.7578\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7094 - accuracy: 0.7578\n",
            "{'accuracy': 0.7577999830245972, 'loss': 0.7093842029571533, 'learning_rate': 0.0001, 'epsilon': 1e-06, 'ema_momentum': 0.999}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 1.9905 - accuracy: 0.2534 - val_loss: 1.6759 - val_accuracy: 0.3912\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6232 - accuracy: 0.3907 - val_loss: 1.4574 - val_accuracy: 0.4661\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4494 - accuracy: 0.4710 - val_loss: 1.4030 - val_accuracy: 0.5025\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3279 - accuracy: 0.5212 - val_loss: 1.1633 - val_accuracy: 0.5851\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2219 - accuracy: 0.5641 - val_loss: 1.0877 - val_accuracy: 0.6181\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1410 - accuracy: 0.5967 - val_loss: 1.0312 - val_accuracy: 0.6403\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0730 - accuracy: 0.6227 - val_loss: 0.9826 - val_accuracy: 0.6605\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0157 - accuracy: 0.6409 - val_loss: 0.9373 - val_accuracy: 0.6676\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9663 - accuracy: 0.6607 - val_loss: 0.8642 - val_accuracy: 0.7007\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9285 - accuracy: 0.6734 - val_loss: 0.8693 - val_accuracy: 0.7015\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8915 - accuracy: 0.6893 - val_loss: 0.8241 - val_accuracy: 0.7193\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8527 - accuracy: 0.7028 - val_loss: 0.8341 - val_accuracy: 0.7167\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8287 - accuracy: 0.7103 - val_loss: 0.7858 - val_accuracy: 0.7325\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7971 - accuracy: 0.7247 - val_loss: 0.7662 - val_accuracy: 0.7361\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7790 - accuracy: 0.7287 - val_loss: 0.7442 - val_accuracy: 0.7464\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7599 - accuracy: 0.7380 - val_loss: 0.7413 - val_accuracy: 0.7486\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7438 - accuracy: 0.7448 - val_loss: 0.7162 - val_accuracy: 0.7561\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7192 - accuracy: 0.7505 - val_loss: 0.7158 - val_accuracy: 0.7554\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7059 - accuracy: 0.7557 - val_loss: 0.6929 - val_accuracy: 0.7666\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6960 - accuracy: 0.7613 - val_loss: 0.6983 - val_accuracy: 0.7651\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6983 - accuracy: 0.7651\n",
            "{'accuracy': 0.7651000022888184, 'loss': 0.698297381401062, 'learning_rate': 0.0001, 'epsilon': 1e-07, 'ema_momentum': 0.99}\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 1.9971 - accuracy: 0.2407 - val_loss: 1.6918 - val_accuracy: 0.3851\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.6085 - accuracy: 0.4008 - val_loss: 1.4098 - val_accuracy: 0.4865\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.4227 - accuracy: 0.4828 - val_loss: 1.3273 - val_accuracy: 0.5200\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2920 - accuracy: 0.5395 - val_loss: 1.1676 - val_accuracy: 0.5791\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1883 - accuracy: 0.5769 - val_loss: 1.0831 - val_accuracy: 0.6103\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1243 - accuracy: 0.6043 - val_loss: 1.0593 - val_accuracy: 0.6210\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.0598 - accuracy: 0.6270 - val_loss: 0.9639 - val_accuracy: 0.6601\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0022 - accuracy: 0.6474 - val_loss: 0.8991 - val_accuracy: 0.6867\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.9580 - accuracy: 0.6634 - val_loss: 0.8772 - val_accuracy: 0.6903\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9183 - accuracy: 0.6818 - val_loss: 0.8870 - val_accuracy: 0.6872\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8839 - accuracy: 0.6901 - val_loss: 0.8495 - val_accuracy: 0.7037\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8455 - accuracy: 0.7057 - val_loss: 0.7856 - val_accuracy: 0.7286\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8253 - accuracy: 0.7142 - val_loss: 0.8045 - val_accuracy: 0.7208\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7961 - accuracy: 0.7238 - val_loss: 0.7646 - val_accuracy: 0.7322\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7736 - accuracy: 0.7302 - val_loss: 0.7398 - val_accuracy: 0.7472\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7564 - accuracy: 0.7395 - val_loss: 0.7635 - val_accuracy: 0.7460\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7367 - accuracy: 0.7464 - val_loss: 0.7041 - val_accuracy: 0.7597\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7187 - accuracy: 0.7512 - val_loss: 0.6983 - val_accuracy: 0.7575\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7040 - accuracy: 0.7569 - val_loss: 0.6984 - val_accuracy: 0.7558\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6904 - accuracy: 0.7606 - val_loss: 0.6950 - val_accuracy: 0.7606\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6950 - accuracy: 0.7606\n",
            "{'accuracy': 0.7605999708175659, 'loss': 0.6949785351753235, 'learning_rate': 0.0001, 'epsilon': 1e-07, 'ema_momentum': 0.999}\n",
            "Лучший результат: 0.773400 с использованием {'accuracy': 0.7734000086784363, 'loss': 0.6701763272285461, 'learning_rate': 0.01, 'epsilon': 1e-06, 'ema_momentum': 0.999}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(grid_result).T.sort_values('accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "LcxSq3Ltof2n",
        "outputId": "e44346f2-c09b-494c-82f6-8c2bbe314ea1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        accuracy      loss  learning_rate       epsilon  ema_momentum\n",
              "0.7496    0.7496  0.737808         0.0100  1.000000e-07         0.999\n",
              "0.7578    0.7578  0.709384         0.0001  1.000000e-06         0.999\n",
              "0.7606    0.7606  0.694979         0.0001  1.000000e-07         0.999\n",
              "0.7621    0.7621  0.706854         0.0010  1.000000e-07         0.999\n",
              "0.7628    0.7628  0.687985         0.0010  1.000000e-06         0.999\n",
              "0.7651    0.7651  0.698297         0.0001  1.000000e-07         0.990\n",
              "0.7659    0.7659  0.695982         0.0010  1.000000e-07         0.990\n",
              "0.7678    0.7678  0.690576         0.0001  1.000000e-06         0.990\n",
              "0.7694    0.7694  0.683381         0.0100  1.000000e-06         0.990\n",
              "0.7701    0.7701  0.678335         0.0010  1.000000e-06         0.990\n",
              "0.7707    0.7707  0.683386         0.0100  1.000000e-07         0.990\n",
              "0.7734    0.7734  0.670176         0.0100  1.000000e-06         0.999"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6913c3f-4fb9-4365-a455-23dba327882a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>epsilon</th>\n",
              "      <th>ema_momentum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.7496</th>\n",
              "      <td>0.7496</td>\n",
              "      <td>0.737808</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1.000000e-07</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7578</th>\n",
              "      <td>0.7578</td>\n",
              "      <td>0.709384</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.000000e-06</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7606</th>\n",
              "      <td>0.7606</td>\n",
              "      <td>0.694979</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.000000e-07</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7621</th>\n",
              "      <td>0.7621</td>\n",
              "      <td>0.706854</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1.000000e-07</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7628</th>\n",
              "      <td>0.7628</td>\n",
              "      <td>0.687985</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1.000000e-06</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7651</th>\n",
              "      <td>0.7651</td>\n",
              "      <td>0.698297</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.000000e-07</td>\n",
              "      <td>0.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7659</th>\n",
              "      <td>0.7659</td>\n",
              "      <td>0.695982</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1.000000e-07</td>\n",
              "      <td>0.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7678</th>\n",
              "      <td>0.7678</td>\n",
              "      <td>0.690576</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.000000e-06</td>\n",
              "      <td>0.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7694</th>\n",
              "      <td>0.7694</td>\n",
              "      <td>0.683381</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1.000000e-06</td>\n",
              "      <td>0.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7701</th>\n",
              "      <td>0.7701</td>\n",
              "      <td>0.678335</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1.000000e-06</td>\n",
              "      <td>0.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7707</th>\n",
              "      <td>0.7707</td>\n",
              "      <td>0.683386</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1.000000e-07</td>\n",
              "      <td>0.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7734</th>\n",
              "      <td>0.7734</td>\n",
              "      <td>0.670176</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1.000000e-06</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6913c3f-4fb9-4365-a455-23dba327882a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6913c3f-4fb9-4365-a455-23dba327882a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6913c3f-4fb9-4365-a455-23dba327882a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Попробовать улучшить точность распознования образов cifar 10 сверточной нейронной сетью, рассмотренной на уроке. Приложить анализ с описанием того, что улучшает работу нейронной сети и что ухудшает.\n",
        "\n",
        "На уроке точность до 70%. В ходе тестов точность доходила до 80%. Последняя глубокая, но за счёт больших пулигов имеет всего 216 тыс. парамеров. Предыдущий вариант по глубине имеет 6,7 млн. параметров. Можно предположить, что там можно было бы получить 85-90% точности. Но обучение такой сети слишком долго и для пробы пера можно обойтись без этого.\n",
        "\n",
        "На улучшение сказывается количество параметров и глубина сети (в пределах разумного). К ухужшению может приводить переобучение, недостаточное количество данных для обучения, неправильный выбор гиперпараметров, неправильный выбор функции активации и т.п.\n",
        "\n",
        "Результаты обучения местами продуюлированы для последующего анализа. Но и так заметно, что последний результат не всегда лучший. Так что это либо временный эффект (из-за локального минимума), либо дальше (с увеличением количества эпох) только переобучение."
      ],
      "metadata": {
        "id": "88XR9vbRpGXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Описать также в анализе какие необоходимо внести изменения в получившуюся у вас нейронную сеть если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET.\n",
        "\n",
        "CIFAR-10 и MNIST - это два разных набора данных для распознавания объектов на изображениях. CIFAR-10 содержит 60 000 цветных изображений размером 32x32 пикселя в 10 различных классах. MNIST содержит 70 000 черно-белых изображений размером 28x28 пикселя в 10 различных классах.\n",
        "\n",
        "CIFAR-100 - это набор данных для распознавания объектов на изображениях, который содержит 60 000 цветных изображений размером 32x32 пикселя в 100 различных классах.\n",
        "\n",
        "ImageNet - это набор данных для распознавания объектов на изображениях, который содержит более миллиона изображений в высоком разрешении.\n",
        "\n",
        "Для того, чтобы на вход могли поступать другие данные, надо модифицировать входной слой `Conv2D`. `input_shape` должен быть по размеру изображения. Первый параметр отвечает за количество фильтров, которые будут применены на первом слое, можно не менять. А второй параметр `kernel_size` (размер ядра, что ли так перевести), показывает какое количество пикселей будут обрабатываться. Так же можно не менять.\n",
        "\n",
        "Выше есть summary последней рабочей сети. Там можно отметить, что после всех свёрток и пулингов получается слой размером (1, 64, 64). А если изображение уменьшается, как в случае в MNIST, то надо учитывать это и обыграть либо на первом слое подобрав падинг, либо на слоях пулинга уменьшить шаг, чтобы не получить нулевое разрешение слоя.\n",
        "\n",
        "Для CIRAR-100 и ImageNet надо указать корректное разрешение выходного слоя.\n",
        "\n",
        "Можно углубить сеть ещё немного, увеличить количество обучаемых параметров, как в предыдущем варианте (где 6,7 млн. параметров), но это сильно скажется на времени обучения. Зато можно получить качество.\n",
        "\n",
        "К каждому датасету нужен индивидуальный подход. Как известно из предыдущих работ, не ясно какая комбиная параметров за преемлемое время покажет лучший результат. Разве что обучаем GPT на огромных ресурсах. Тогда можно ставить что-то приблизительно и обучать от души. Правда, даже там придётся при переобучении (или остановке обучения) менять параметры функций активаций и функций потерь, чтобы макимально близко подобраться к локальным минимумам."
      ],
      "metadata": {
        "id": "k42qlp8NhVBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PS Для выполнения дз подребовалось задействовать кучу ресурсов. Colab похоже, как только встречает Grid любой для обучения, сразу ставит задачу в очередь. Хорошо, если через 30 минут возьмут в работу, а то могут и за 3 часа ничего не сделать. Плюс в бесплатной версии не закрыть страницу. А деньги им не заплатить (10 usd в месяц) по известным причинам. Запуск вычислений на компе с cuda не успешен, т.к. память (6 Гб) на гпу заканчивается мгновенно и всё падает. На ограничения tensorflow что-то не реагирует. Надо изучать этот момент. При этом в colab-е (по их метрикам) используется порядка 5,5 Гб. Может им не нужна графика. Запуск на ЦПУ (с индивидуальной сборкой с avx и avx2) был оцень перспективен. Но очередной раз привёл к падению conda с браузером. Похоже опять память (16 гб ОЗУ + 16 гб своп мало).\n",
        "\n",
        "Пришлось чтобы в очереди долгой не стоять на ресурсы в colab использовать циклы. Не супер решение, но пока сработало."
      ],
      "metadata": {
        "id": "MxJkmO60lYGP"
      }
    }
  ]
}