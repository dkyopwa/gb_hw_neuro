{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e05707b-f7a2-49ed-9530-477eb626426f",
   "metadata": {
    "id": "7e05707b-f7a2-49ed-9530-477eb626426f"
   },
   "source": [
    "# Hometask 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197c4c1-7cc0-46a7-b09f-7dbefa9af848",
   "metadata": {
    "id": "8197c4c1-7cc0-46a7-b09f-7dbefa9af848"
   },
   "source": [
    "**Домашнее задание**:\n",
    "\n",
    "Попробуйте обучить, нейронную сеть на Keras (рассмотренную на уроке) на датасете MNIST с другими параметрами. Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?\n",
    "\n",
    "Поработайте с документацией Keras. Попробуйте найти полезные команды Keras неразобранные на уроке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6c618c-800b-49bb-8e80-2d0493d1176d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8376,
     "status": "ok",
     "timestamp": 1681101966111,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "dd6c618c-800b-49bb-8e80-2d0493d1176d",
    "outputId": "9966a624-0da6-4da8-d9b7-ef9d196b785c"
   },
   "outputs": [],
   "source": [
    "# !pip install keras tensorflow plotly scikeras\n",
    "# !pip install scikeras\n",
    "# !activate tensorflow\n",
    "# ! pip install tensorflow\n",
    "# !pip freeze\n",
    "# import tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b45285-2b34-4c8b-8ef7-af4739528542",
   "metadata": {
    "executionInfo": {
     "elapsed": 4506,
     "status": "ok",
     "timestamp": 1681101970606,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "a2b45285-2b34-4c8b-8ef7-af4739528542"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 13:33:47.359236: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-11 13:33:48.885201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c02387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 13:33:50.603920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 13:33:50.674810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 13:33:50.674919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 13:33:50.678892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 13:33:50.679028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 13:33:50.679095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 13:33:51.949767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 13:33:51.949814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 13:33:51.949985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 13:33:51.950062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 13:33:51.950092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=1024 * 4)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1491aa2-2aca-4aea-a518-f553de4a4d91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1681101970607,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "b1491aa2-2aca-4aea-a518-f553de4a4d91",
    "outputId": "5bf521d9-3db4-4f0f-a2d7-e431736b2afd"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0855df-ea1f-4ed6-8de7-736cfab69673",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1681101970983,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "be0855df-ea1f-4ed6-8de7-736cfab69673",
    "outputId": "1075f49b-2b48-4328-c5ed-373cd2160eb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min(), X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d239772-090d-4923-814f-835aab013774",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1681101970984,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "8d239772-090d-4923-814f-835aab013774",
    "outputId": "ac05d108-6beb-46e8-cfbb-e658ac34ac8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6614f9a0-2a5d-4c8d-942b-05b705b28118",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1681101970985,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "6614f9a0-2a5d-4c8d-942b-05b705b28118",
    "outputId": "67151439-096e-4e84-b10e-588e2b187357"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, (60000, 28, 28))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].size, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "782dab37-3db3-4c83-92b6-04b84ce9cca4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1681101970986,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "782dab37-3db3-4c83-92b6-04b84ce9cca4",
    "outputId": "b9f297e9-0b05-4a9f-c3c9-ad6296e3ecff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].size ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f8c061-5f36-481c-a206-f635a0b657e9",
   "metadata": {
    "id": "f9f8c061-5f36-481c-a206-f635a0b657e9"
   },
   "source": [
    "Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cf6d66-2949-4028-a2ec-ef4234fdfe26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "executionInfo": {
     "elapsed": 2067,
     "status": "ok",
     "timestamp": 1681101973046,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "76cf6d66-2949-4028-a2ec-ef4234fdfe26",
    "outputId": "55e350f7-b859-410e-9c59-57188973f23b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 5)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(2):\n",
    "        axes[j][i].imshow(X_train[i + j * 5], cmap='gray')\n",
    "        axes[j][i].set_title(y_train[i + j * 5])\n",
    "\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb41eb-c693-41d8-9d37-7be495a31e93",
   "metadata": {
    "id": "37bb41eb-c693-41d8-9d37-7be495a31e93"
   },
   "source": [
    "Сделаем базовую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05eeeb11-d0ec-4407-9ce1-d3a282d6b8e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1681101973047,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "05eeeb11-d0ec-4407-9ce1-d3a282d6b8e4",
    "outputId": "2b953d20-5127-4935-8f22-099c37a2d7ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape((-1, X_train[0].size))\n",
    "X_test = X_test.reshape((-1, X_train[0].size))\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "564cca17-286c-4b4f-ba50-c382bf155bd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3294,
     "status": "ok",
     "timestamp": 1681101976330,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "564cca17-286c-4b4f-ba50-c382bf155bd5",
    "outputId": "da0a390e-cb1b-4a20-c41f-4d9815f7a655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,650\n",
      "Trainable params: 52,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 152 ms, sys: 37.2 ms, total: 189 ms\n",
      "Wall time: 338 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(64, input_shape=(X_train[0].size, ), activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model1.save_weights('model_64_32_10_rs.h5')\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a5088a-752f-466a-a180-1c8fa35dd3e7",
   "metadata": {
    "id": "06a5088a-752f-466a-a180-1c8fa35dd3e7"
   },
   "source": [
    "Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd12b12a-b8ad-40be-89c0-211e93482b7e",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1681101976332,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "cd12b12a-b8ad-40be-89c0-211e93482b7e"
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea237da-9bbf-4f32-bfda-596b9ed92d50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19477,
     "status": "ok",
     "timestamp": 1681101995798,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "2ea237da-9bbf-4f32-bfda-596b9ed92d50",
    "outputId": "a3cd9d37-7663-4c50-cdb5-d0ada0124942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 13:33:55.296811: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fdf30009f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-11 13:33:55.296892: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1060, Compute Capability 6.1\n",
      "2023-04-11 13:33:55.588328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-11 13:33:55.809574: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-11 13:33:55.923164: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 4s 10ms/step - loss: 1.7344 - accuracy: 0.5156 - val_loss: 1.0966 - val_accuracy: 0.7667\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.8146 - accuracy: 0.8137 - val_loss: 0.6138 - val_accuracy: 0.8508\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5509 - accuracy: 0.8600 - val_loss: 0.4760 - val_accuracy: 0.8765\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.4572 - accuracy: 0.8774 - val_loss: 0.4139 - val_accuracy: 0.8874\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4090 - accuracy: 0.8878 - val_loss: 0.3788 - val_accuracy: 0.8951\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3788 - accuracy: 0.8951\n",
      "test loss, test acc: [0.3788391053676605, 0.8950999975204468]\n"
     ]
    }
   ],
   "source": [
    "model1.load_weights('model_64_32_10_rs.h5')\n",
    "\n",
    "# Train the model\n",
    "model1.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results = model1.evaluate(X_test, y_test)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c1a894-285e-4433-90fb-4ff2d20d3295",
   "metadata": {
    "id": "90c1a894-285e-4433-90fb-4ff2d20d3295"
   },
   "source": [
    "Сделаем валидаю на train данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12b4b940-46ef-40ba-adc9-be8757e80db5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7227,
     "status": "ok",
     "timestamp": 1681102007960,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "12b4b940-46ef-40ba-adc9-be8757e80db5",
    "outputId": "81cd776c-a2c2-489c-f86b-c931af1df391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 1.8673 - accuracy: 0.4531 - val_loss: 1.3225 - val_accuracy: 0.7181\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.9924 - accuracy: 0.7790 - val_loss: 0.7185 - val_accuracy: 0.8406\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.6465 - accuracy: 0.8424 - val_loss: 0.5288 - val_accuracy: 0.8706\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.5183 - accuracy: 0.8666 - val_loss: 0.4478 - val_accuracy: 0.8842\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.4548 - accuracy: 0.8785 - val_loss: 0.4029 - val_accuracy: 0.8923\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4122 - accuracy: 0.8901\n",
      "test loss, test acc: [0.41224637627601624, 0.8901000022888184]\n"
     ]
    }
   ],
   "source": [
    "model1.load_weights('model_64_32_10_rs.h5')\n",
    "\n",
    "# Train the model\n",
    "model1.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results = model1.evaluate(X_test, y_test)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ef94e0-e85b-48fd-9ccb-0fbe1faa6a3e",
   "metadata": {
    "id": "b2ef94e0-e85b-48fd-9ccb-0fbe1faa6a3e"
   },
   "source": [
    "Для перебора разных параметров и при изучении матчасти оказалось, что для применения GridSearchCV необходимо использовать KerasClassifier, куда надо передавать функцию создающую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1446a93b-8cb0-43cb-8daf-ebb97bd56994",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1681102007960,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "1446a93b-8cb0-43cb-8daf-ebb97bd56994"
   },
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef531191-042a-41de-81dc-0fbddb1514fc",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1681102009972,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "ef531191-042a-41de-81dc-0fbddb1514fc"
   },
   "outputs": [],
   "source": [
    "# loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'], activation_layers='relu', activation_last='sigmoid'\n",
    "def create_model1(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'], activation_layers='relu', activation_last='sigmoid'):\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(64, input_shape=(X_train[0].size, ), activation='relu'))\n",
    "    model1.add(Dense(32, activation='relu'))\n",
    "    model1.add(Dense(10, activation='sigmoid'))\n",
    "    \n",
    "    model1.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d5fcf72-72d9-493e-a309-9e8164e4a60a",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681102011633,
     "user": {
      "displayName": "Vladimir Nedved",
      "userId": "09538879974077919771"
     },
     "user_tz": -180
    },
    "id": "6d5fcf72-72d9-493e-a309-9e8164e4a60a"
   },
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'epochs':[5, 10, 15],\n",
    "    'batch_size':[256, 512, 1024],\n",
    "    'loss':['poisson', 'binary_crossentropy', 'categorical_crossentropy'],\n",
    "    'optimizer':['SGD', 'RMSprop', 'Adam'], #, 'Adagrad', 'Adamax'],\n",
    "    'metrics':['accuracy', 'binary_crossentropy', 'hinge'],\n",
    "    'activation_layers':['relu', 'elu', 'selu'],\n",
    "    'activation_last':['tanh', 'sigmoid'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b9277",
   "metadata": {},
   "source": [
    "Попытка ручного подбора параметров для последующего анализа наиболее эффективных параметров - не успешна. Похоже есть какой-то таймаут на работу ноутбука. И соответственно оставить компьютер без присмотра на посчитать не получается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ae53c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# def custom_grid_search(func_create_model=None):\n",
    "#     best_params = dict()\n",
    "#     history = list()\n",
    "    \n",
    "#     t = 1\n",
    "#     for k in params_grid.keys():\n",
    "#         t *= len(params_grid[k])\n",
    "#     print('Calculated hits {}'.format(t))\n",
    "#     i = 0\n",
    "\n",
    "#     for epoch in params_grid['epochs']:\n",
    "#         for batch_size in params_grid['batch_size']:\n",
    "#             for optimizer in params_grid['optimizer']:\n",
    "#                 for metrics in params_grid['metrics']:\n",
    "#                     for activation_layers in params_grid['activation_layers']:\n",
    "#                         for activation_last in params_grid['activation_last']:\n",
    "#                             for loss in params_grid['loss']:\n",
    "#                                 model1 = func_create_model(loss=loss, optimizer=optimizer, metrics=[metrics], activation_layers=activation_layers, activation_last=activation_last)\n",
    "#                                 model1.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "\n",
    "#                                 results = model1.evaluate(X_test, y_test)\n",
    "#                                 print('test loss, test acc:', results)\n",
    "\n",
    "#                                 if results[1] > best_params.get('acc', 99999999):\n",
    "#                                     best_params['acc'] = results[1]\n",
    "#                                     best_params['loss'] = results[0]\n",
    "#                                     best_params['loss_type'] = loss\n",
    "#                                     best_params['epoch'] = epoch\n",
    "#                                     best_params['batch_size'] = batch_size\n",
    "#                                     best_params['optimizer'] = optimizer\n",
    "#                                     best_params['metrics'] = metrics\n",
    "#                                     best_params['activation_layers'] = activation_layers\n",
    "#                                     best_params['activation_last'] - activation_last\n",
    "\n",
    "#                                 history.append([results[1], results[0], loss, epoch, batch_size, optimizer, metrics, activation_layers, activation_last])\n",
    "                                \n",
    "#                                 i += 1\n",
    "#                                 print('ITER = {}/{}'.format(i, t))\n",
    "\n",
    "#     return best_params, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93639d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_results(best_params, history):\n",
    "#     history = pd.DataFrame(history, columns=['acc', 'loss', 'loss_type', 'epoch', 'batch_size', 'optimizer', 'metrics', 'activation_layers', 'activation_last'])\n",
    "#     history.sort_values('loss', axis=0, ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87692e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params1, history1 = custom_grid_search(create_model1)\n",
    "# calc_results(best_params1, history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5ce53d",
   "metadata": {},
   "source": [
    "Очередная попытка использовать GridSearchCV тоже не успешна. Google colab нужны деньги, т.к. серьезные ресурсы на посчитать просто не дождаться. Локально (даже с учётом вычислений на видеркарте) тоже надо слишком много времени. И как оказалось памяти. Чем больше потоков запускается, тем больше памяти требуется на видеокарте. Для одного птока выделяет практически всю свободную память (подяка 4-5 Гб), а дальше (то ли на поток, то ли на новую итерацию) пытается снова выделить память, которой нет (в общем ни оперативной (там хоть свап есть), ни на карте). Сделано для избежания фрагментации памяти. Но здесь и данных то не так много. Где-то есть не слишком эффективная работа с памятью. Но что-то не получилось разобраться, даже с попыткой её ограничения. Всё равно пытается выделить больше.\n",
    "\n",
    "Ещё одно место медленного выполнения это `cv` - слишком много валидаций. Это хороший вариант для качественного обучения, но для подбора параметров слишком долго."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3586e034-c8de-4d65-b8e2-644ca109d486",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3586e034-c8de-4d65-b8e2-644ca109d486",
    "outputId": "74540278-0564-4853-f576-dc22e78aea06",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 6.68 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# model1 = KerasClassifier(build_fn=create_model1, optimizer=None, metrics=None, activation_layers=None, activation_last=None)\n",
    "\n",
    "# grid = GridSearchCV(estimator=model1, param_grid=params_grid, cv=2, n_jobs=2, verbose=1)\n",
    "# grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a9c32be-d632-4466-8351-4c8fcd2678b1",
   "metadata": {
    "id": "0a9c32be-d632-4466-8351-4c8fcd2678b1"
   },
   "outputs": [],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# df_result = pd.DataFrame(grid_result.cv_results_)\n",
    "# df_result.sort_values('rank_test_score', axis=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b1480a6-8c5b-4de4-98a0-55e3beea41af",
   "metadata": {
    "id": "6b1480a6-8c5b-4de4-98a0-55e3beea41af"
   },
   "outputs": [],
   "source": [
    "# df_result.sort_values('rank_test_score', axis=0, ascending=False)['params'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd127553-7ba8-46ca-8dc1-003349b193ab",
   "metadata": {
    "id": "fd127553-7ba8-46ca-8dc1-003349b193ab"
   },
   "source": [
    "При малом количестве параметров удалось запустить, и получить какие-то результаты. Но при полноценном подборе воспроизвести не удалось.\n",
    "\n",
    "Лучшая функция потерь - `sparse_categorical_crossentropy`, лучшая метрика - `hinge` (хотя на втором месте `accuracy`, так что разница не большая), батч в 256 айтемов эффективнее чем 32 и 1024, а эпох - 10 (судя по топу результатов, хотя там есть и 20 и 5). При этом функция потерь `sparse_categorical_crossentropy` для данного набора не должна была работать. Либо если и работать то не в ланном виде, как представлены данные. Случайный результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ceb04-2084-47f2-bbfa-8d1c71efd8e5",
   "metadata": {
    "id": "944ceb04-2084-47f2-bbfa-8d1c71efd8e5"
   },
   "source": [
    "Судя по результатам однозначно сказать, что какая-то комбиная победит нельзя. Но есть определённые параметры, которые могут привести в конкретной задаче к более/менее макисмально возным результатам обучения сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c87bd-2b9c-4a9b-b51a-b4adb0e155d7",
   "metadata": {
    "id": "ed1c87bd-2b9c-4a9b-b51a-b4adb0e155d7"
   },
   "source": [
    "Сделаем другой вариант сети и снова обучим. Возьмём что-нибудь до 70 тыс. параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea72f49d-616b-4c68-91e6-69f06c91a2b0",
   "metadata": {
    "id": "ea72f49d-616b-4c68-91e6-69f06c91a2b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 88)                69080     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                890       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,970\n",
      "Trainable params: 69,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(88, input_shape=(X_train[0].size, ), activation='relu'))\n",
    "model2.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12894925-8658-4f8e-8c79-b6f8e80616d4",
   "metadata": {
    "id": "12894925-8658-4f8e-8c79-b6f8e80616d4"
   },
   "outputs": [],
   "source": [
    "def create_model2(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'], activation_layers='relu', activation_last='sigmoid'):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(88, input_shape=(X_train[0].size, ), activation='relu'))\n",
    "    model2.add(Dense(10, activation='sigmoid'))\n",
    "    \n",
    "    model2.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b003491d-099e-40e6-b1f0-e2d8857e9162",
   "metadata": {
    "id": "b003491d-099e-40e6-b1f0-e2d8857e9162"
   },
   "outputs": [],
   "source": [
    "# model2 = KerasClassifier(model=create_model2, optimizer=None, metrics=None, activation_layers=None, activation_last=None)\n",
    "\n",
    "# grid = GridSearchCV(estimator=model2, param_grid=params_grid, n_jobs=-1, cv=3, verbose=1)\n",
    "# grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f8523c3-8c65-42de-ae1b-10ea74f2801d",
   "metadata": {
    "id": "5f8523c3-8c65-42de-ae1b-10ea74f2801d"
   },
   "outputs": [],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# df_result = pd.DataFrame(grid_result.cv_results_)\n",
    "# df_result.sort_values('rank_test_score', axis=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba7a960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params2, history2 = custom_grid_search(create_model2)\n",
    "# calc_results(best_params2, history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921160fa-e613-4ac4-bfe9-99896d737f81",
   "metadata": {
    "id": "921160fa-e613-4ac4-bfe9-99896d737f81"
   },
   "source": [
    "Сделаем ещё одну сеть (более глубокую), до 70 тыс. параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4480a4a1-e59f-4a9d-8c5e-faed1bffaf93",
   "metadata": {
    "id": "4480a4a1-e59f-4a9d-8c5e-faed1bffaf93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 54)                42390     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 48)                2640      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 40)                1960      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                1312      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,000\n",
      "Trainable params: 49,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(54, input_shape=(X_train[0].size, ), activation='relu'))\n",
    "model3.add(Dense(48, activation='relu'))\n",
    "model3.add(Dense(40, activation='relu'))\n",
    "model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dense(16, activation='relu'))\n",
    "model3.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8e018ed-7b60-44b7-8245-25fd46dbea40",
   "metadata": {
    "id": "e8e018ed-7b60-44b7-8245-25fd46dbea40"
   },
   "outputs": [],
   "source": [
    "def create_model3(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'], activation_layers='relu', activation_last='sigmoid'):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(54, input_shape=(X_train[0].size, ), activation='relu'))\n",
    "    model3.add(Dense(48, activation='relu'))\n",
    "    model3.add(Dense(40, activation='relu'))\n",
    "    model3.add(Dense(32, activation='relu'))\n",
    "    model3.add(Dense(16, activation='relu'))\n",
    "    model3.add(Dense(10, activation='sigmoid'))\n",
    "    \n",
    "    model3.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85a70f22-b65a-4767-882e-c68dfb346dc5",
   "metadata": {
    "id": "85a70f22-b65a-4767-882e-c68dfb346dc5"
   },
   "outputs": [],
   "source": [
    "# model3 = KerasClassifier(model=create_model3, optimizer=None, metrics=None, activation_layers=None, activation_last=None)\n",
    "\n",
    "# grid = GridSearchCV(estimator=model3, param_grid=params_grid, n_jobs=-1, cv=3, verbose=1)\n",
    "# grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9ee8523-e551-44e8-b1c4-1e20aac7ad31",
   "metadata": {
    "id": "d9ee8523-e551-44e8-b1c4-1e20aac7ad31"
   },
   "outputs": [],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# df_result = pd.DataFrame(grid_result.cv_results_)\n",
    "# df_result.sort_values('rank_test_score', axis=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a542f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params3, history3 = custom_grid_search(create_model3)\n",
    "# calc_results(best_params3, history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec36a24e-2362-4ac3-9493-2814b094c22c",
   "metadata": {
    "id": "ec36a24e-2362-4ac3-9493-2814b094c22c"
   },
   "source": [
    "Попробуем что-нибудь новое, типа Dropout слоя. Оценим эффект."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8fe2fa4-1f02-4b85-85ed-90840b0dbf86",
   "metadata": {
    "id": "b8fe2fa4-1f02-4b85-85ed-90840b0dbf86"
   },
   "outputs": [],
   "source": [
    "def create_model4(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'], activation_layers='relu', activation_last='sigmoid'):\n",
    "    model4 = Sequential()\n",
    "    model4.add(Dense(64, input_shape=(X_train[0].size, ), activation='relu'))\n",
    "    model4.add(Dropout(0.2))\n",
    "    model4.add(Dense(32, activation='relu'))\n",
    "    model4.add(Dropout(0.3))\n",
    "    model4.add(Dense(10, activation='sigmoid'))\n",
    "    \n",
    "    model4.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30e2c5b1-91b6-4d94-a714-3fd7fa69bec4",
   "metadata": {
    "id": "30e2c5b1-91b6-4d94-a714-3fd7fa69bec4"
   },
   "outputs": [],
   "source": [
    "# model4 = KerasClassifier(model=create_model4, optimizer=None, metrics=None, activation_layers=None, activation_last=None)\n",
    "\n",
    "# grid = GridSearchCV(estimator=model4, param_grid=params_grid, n_jobs=-1, cv=3, verbose=1)\n",
    "# grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21b930e9-2e17-4489-8d40-f3ac98e3bdee",
   "metadata": {
    "id": "21b930e9-2e17-4489-8d40-f3ac98e3bdee"
   },
   "outputs": [],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# df_result = pd.DataFrame(grid_result.cv_results_)\n",
    "# df_result.sort_values('rank_test_score', axis=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3c2a0cd-c996-401f-bc07-8734091a6962",
   "metadata": {
    "id": "f3c2a0cd-c996-401f-bc07-8734091a6962"
   },
   "outputs": [],
   "source": [
    "# best_params4, history4 = custom_grid_search(create_model4)\n",
    "# calc_results(best_params4, history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e50dd5",
   "metadata": {},
   "source": [
    "В результате будем делать ручной подбор по одному параметру за раз.\n",
    "\n",
    "Начнём с функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eca9aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.3292 - accuracy: 0.2151\n",
      "test loss, test acc: [0.32917872071266174, 0.2151000052690506]\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.3639\n",
      "test loss, test acc: [0.3147542476654053, 0.36390000581741333]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6616 - accuracy: 0.8303\n",
      "test loss, test acc: [0.6616070866584778, 0.830299973487854]\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.3130\n",
      "test loss, test acc: [0.3246877193450928, 0.31299999356269836]\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3091 - accuracy: 0.4128\n",
      "test loss, test acc: [0.3090948164463043, 0.41280001401901245]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.6647 - accuracy: 0.8490\n",
      "test loss, test acc: [0.664739191532135, 0.8489999771118164]\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.1269\n",
      "test loss, test acc: [0.3491126000881195, 0.12690000236034393]\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.1393\n",
      "test loss, test acc: [0.33517739176750183, 0.13930000364780426]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1069 - accuracy: 0.6746\n",
      "test loss, test acc: [1.1068865060806274, 0.6746000051498413]\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.2022\n",
      "test loss, test acc: [0.3412618339061737, 0.2021999955177307]\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3225 - accuracy: 0.2663\n",
      "test loss, test acc: [0.32247021794319153, 0.2662999927997589]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.9427 - accuracy: 0.8117\n",
      "test loss, test acc: [0.942695140838623, 0.8116999864578247]\n",
      "CPU times: user 1min 19s, sys: 28.6 s, total: 1min 48s\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>loss_func</th>\n",
       "      <th>loss_err</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.309095</td>\n",
       "      <td>0.4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.314754</td>\n",
       "      <td>0.3639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.322470</td>\n",
       "      <td>0.2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>poisson</td>\n",
       "      <td>0.324688</td>\n",
       "      <td>0.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>poisson</td>\n",
       "      <td>0.329179</td>\n",
       "      <td>0.2151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.335177</td>\n",
       "      <td>0.1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>poisson</td>\n",
       "      <td>0.341262</td>\n",
       "      <td>0.2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>poisson</td>\n",
       "      <td>0.349113</td>\n",
       "      <td>0.1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>0.661607</td>\n",
       "      <td>0.8303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>0.664739</td>\n",
       "      <td>0.8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>0.942695</td>\n",
       "      <td>0.8117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>1.106887</td>\n",
       "      <td>0.6746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model                 loss_func  loss_err     acc\n",
       "4       2       binary_crossentropy  0.309095  0.4128\n",
       "1       1       binary_crossentropy  0.314754  0.3639\n",
       "10      4       binary_crossentropy  0.322470  0.2663\n",
       "3       2                   poisson  0.324688  0.3130\n",
       "0       1                   poisson  0.329179  0.2151\n",
       "7       3       binary_crossentropy  0.335177  0.1393\n",
       "9       4                   poisson  0.341262  0.2022\n",
       "6       3                   poisson  0.349113  0.1269\n",
       "2       1  categorical_crossentropy  0.661607  0.8303\n",
       "5       2  categorical_crossentropy  0.664739  0.8490\n",
       "11      4  categorical_crossentropy  0.942695  0.8117\n",
       "8       3  categorical_crossentropy  1.106887  0.6746"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results_list = list()\n",
    "\n",
    "for i, func_create_model in enumerate([create_model1, create_model2, create_model3, create_model4]):\n",
    "    weight_flag = False\n",
    "    for loss in params_grid['loss']:\n",
    "        model = func_create_model(loss=loss)\n",
    "        if not weight_flag:\n",
    "            model.save_weights('model1.h5')\n",
    "            weight_flag = True\n",
    "        else:\n",
    "            model.load_weights('model1.h5')\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=1024, validation_split=0.2, verbose=0)\n",
    "\n",
    "        results = model.evaluate(X_test, y_test)\n",
    "        print('test loss, test acc:', results)\n",
    "\n",
    "        # model, loss, loss_err, acc\n",
    "        results_list.append([i + 1, loss, results[0], results[1]])\n",
    "\n",
    "df_results = pd.DataFrame(results_list, columns=['model', 'loss_func', 'loss_err', 'acc'])\n",
    "df_results.sort_values('loss_err', axis=0, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c55fa4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>loss_func</th>\n",
       "      <th>loss_err</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>0.664739</td>\n",
       "      <td>0.8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>0.661607</td>\n",
       "      <td>0.8303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>0.942695</td>\n",
       "      <td>0.8117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>1.106887</td>\n",
       "      <td>0.6746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.309095</td>\n",
       "      <td>0.4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.314754</td>\n",
       "      <td>0.3639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>poisson</td>\n",
       "      <td>0.324688</td>\n",
       "      <td>0.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.322470</td>\n",
       "      <td>0.2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>poisson</td>\n",
       "      <td>0.329179</td>\n",
       "      <td>0.2151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>poisson</td>\n",
       "      <td>0.341262</td>\n",
       "      <td>0.2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.335177</td>\n",
       "      <td>0.1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>poisson</td>\n",
       "      <td>0.349113</td>\n",
       "      <td>0.1269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model                 loss_func  loss_err     acc\n",
       "5       2  categorical_crossentropy  0.664739  0.8490\n",
       "2       1  categorical_crossentropy  0.661607  0.8303\n",
       "11      4  categorical_crossentropy  0.942695  0.8117\n",
       "8       3  categorical_crossentropy  1.106887  0.6746\n",
       "4       2       binary_crossentropy  0.309095  0.4128\n",
       "1       1       binary_crossentropy  0.314754  0.3639\n",
       "3       2                   poisson  0.324688  0.3130\n",
       "10      4       binary_crossentropy  0.322470  0.2663\n",
       "0       1                   poisson  0.329179  0.2151\n",
       "9       4                   poisson  0.341262  0.2022\n",
       "7       3       binary_crossentropy  0.335177  0.1393\n",
       "6       3                   poisson  0.349113  0.1269"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values('acc', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dfa238",
   "metadata": {},
   "source": [
    "По результатам выбираем `categorical_crossentropy` функцию потерь, т.к. в нашем случае одна местрика и можно анализировать по ней."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5539f1",
   "metadata": {},
   "source": [
    "Проанализируем как размет батча влияет на обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7dfbc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4501 - accuracy: 0.8848\n",
      "test loss, test acc: [0.45006757974624634, 0.8848000168800354]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.7123 - accuracy: 0.8311\n",
      "test loss, test acc: [0.7123497724533081, 0.8310999870300293]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2027 - accuracy: 0.7217\n",
      "test loss, test acc: [1.2027086019515991, 0.7217000126838684]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4621 - accuracy: 0.8834\n",
      "test loss, test acc: [0.4621286988258362, 0.883400022983551]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6552 - accuracy: 0.8470\n",
      "test loss, test acc: [0.6552147269248962, 0.847000002861023]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0065 - accuracy: 0.7934\n",
      "test loss, test acc: [1.0064692497253418, 0.79339998960495]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5056 - accuracy: 0.8510\n",
      "test loss, test acc: [0.5055721402168274, 0.8510000109672546]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.3661 - accuracy: 0.6261\n",
      "test loss, test acc: [1.36605703830719, 0.6261000037193298]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 2.1299 - accuracy: 0.2699\n",
      "test loss, test acc: [2.129873275756836, 0.26989999413490295]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.5714 - accuracy: 0.8646\n",
      "test loss, test acc: [0.5713828802108765, 0.8646000027656555]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0031 - accuracy: 0.8018\n",
      "test loss, test acc: [1.003073811531067, 0.801800012588501]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.6478 - accuracy: 0.6479\n",
      "test loss, test acc: [1.6477625370025635, 0.6478999853134155]\n",
      "CPU times: user 1min 30s, sys: 40 s, total: 2min 10s\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>loss_err</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.450068</td>\n",
       "      <td>0.8848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.462129</td>\n",
       "      <td>0.8834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>0.571383</td>\n",
       "      <td>0.8646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.505572</td>\n",
       "      <td>0.8510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.655215</td>\n",
       "      <td>0.8470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.712350</td>\n",
       "      <td>0.8311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "      <td>1.003074</td>\n",
       "      <td>0.8018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>1.006469</td>\n",
       "      <td>0.7934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1.202709</td>\n",
       "      <td>0.7217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>1.647763</td>\n",
       "      <td>0.6479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>1.366057</td>\n",
       "      <td>0.6261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.129873</td>\n",
       "      <td>0.2699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  batch_size  loss_err     acc\n",
       "0       1         256  0.450068  0.8848\n",
       "3       2         256  0.462129  0.8834\n",
       "9       4         256  0.571383  0.8646\n",
       "6       3         256  0.505572  0.8510\n",
       "4       2         512  0.655215  0.8470\n",
       "1       1         512  0.712350  0.8311\n",
       "10      4         512  1.003074  0.8018\n",
       "5       2        1024  1.006469  0.7934\n",
       "2       1        1024  1.202709  0.7217\n",
       "11      4        1024  1.647763  0.6479\n",
       "7       3         512  1.366057  0.6261\n",
       "8       3        1024  2.129873  0.2699"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results_list = list()\n",
    "weight_flag = dict()\n",
    "\n",
    "for i, func_create_model in enumerate([create_model1, create_model2, create_model3, create_model4]):\n",
    "    weight_flag[i] = False\n",
    "    for batch_size in params_grid['batch_size']:\n",
    "        model = func_create_model(loss='categorical_crossentropy')\n",
    "        if not weight_flag[i]:\n",
    "            model.save_weights('model{}.h5'.format(i))\n",
    "            weight_flag[i] = True\n",
    "        else:\n",
    "            model.load_weights('model{}.h5'.format(i))\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "\n",
    "        results = model.evaluate(X_test, y_test)\n",
    "        print('test loss, test acc:', results)\n",
    "\n",
    "        # model, loss, loss_err, acc\n",
    "        results_list.append([i + 1, batch_size, results[0], results[1]])\n",
    "\n",
    "df_results = pd.DataFrame(results_list, columns=['model', 'batch_size', 'loss_err', 'acc'])\n",
    "df_results.sort_values('acc', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc78f4c",
   "metadata": {},
   "source": [
    "Лучшие результаты на batch-е 256, его и продолжим использовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23fd6ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': [5, 10, 15],\n",
       " 'batch_size': [256, 512, 1024],\n",
       " 'loss': ['poisson', 'binary_crossentropy', 'categorical_crossentropy'],\n",
       " 'optimizer': ['SGD', 'RMSprop', 'Adam'],\n",
       " 'metrics': ['accuracy', 'binary_crossentropy', 'hinge'],\n",
       " 'activation_layers': ['relu', 'elu', 'selu'],\n",
       " 'activation_last': ['tanh', 'sigmoid']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ea175",
   "metadata": {},
   "source": [
    "Поменяем функции активации в скрытых слоях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74246c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4324 - accuracy: 0.8914\n",
      "test loss, test acc: [0.4323614239692688, 0.8913999795913696]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4321 - accuracy: 0.8916\n",
      "test loss, test acc: [0.432068407535553, 0.8916000127792358]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4338 - accuracy: 0.8892\n",
      "test loss, test acc: [0.4338372051715851, 0.88919997215271]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4523 - accuracy: 0.8857\n",
      "test loss, test acc: [0.4522746205329895, 0.885699987411499]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4518 - accuracy: 0.8859\n",
      "test loss, test acc: [0.451846718788147, 0.8859000205993652]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4518 - accuracy: 0.8856\n",
      "test loss, test acc: [0.4517730474472046, 0.8855999708175659]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4827 - accuracy: 0.8561\n",
      "test loss, test acc: [0.48268643021583557, 0.8561000227928162]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5014 - accuracy: 0.8531\n",
      "test loss, test acc: [0.5014277100563049, 0.8531000018119812]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4828 - accuracy: 0.8584\n",
      "test loss, test acc: [0.48284414410591125, 0.8583999872207642]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5912 - accuracy: 0.8623\n",
      "test loss, test acc: [0.5912274718284607, 0.8622999787330627]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5905 - accuracy: 0.8616\n",
      "test loss, test acc: [0.5905137658119202, 0.8615999817848206]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5894 - accuracy: 0.8629\n",
      "test loss, test acc: [0.5894190073013306, 0.8629000186920166]\n",
      "CPU times: user 2min 4s, sys: 59 s, total: 3min 3s\n",
      "Wall time: 2min 27s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>activation_layers</th>\n",
       "      <th>loss_err</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.432068</td>\n",
       "      <td>0.8916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.432361</td>\n",
       "      <td>0.8914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>selu</td>\n",
       "      <td>0.433837</td>\n",
       "      <td>0.8892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.451847</td>\n",
       "      <td>0.8859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.452275</td>\n",
       "      <td>0.8857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>selu</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.8856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>selu</td>\n",
       "      <td>0.589419</td>\n",
       "      <td>0.8629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.591227</td>\n",
       "      <td>0.8623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.590514</td>\n",
       "      <td>0.8616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>selu</td>\n",
       "      <td>0.482844</td>\n",
       "      <td>0.8584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.482686</td>\n",
       "      <td>0.8561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.501428</td>\n",
       "      <td>0.8531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model activation_layers  loss_err     acc\n",
       "1       1               elu  0.432068  0.8916\n",
       "0       1              relu  0.432361  0.8914\n",
       "2       1              selu  0.433837  0.8892\n",
       "4       2               elu  0.451847  0.8859\n",
       "3       2              relu  0.452275  0.8857\n",
       "5       2              selu  0.451773  0.8856\n",
       "11      4              selu  0.589419  0.8629\n",
       "9       4              relu  0.591227  0.8623\n",
       "10      4               elu  0.590514  0.8616\n",
       "8       3              selu  0.482844  0.8584\n",
       "6       3              relu  0.482686  0.8561\n",
       "7       3               elu  0.501428  0.8531"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results_list = list()\n",
    "weight_flag = dict()\n",
    "\n",
    "for i, func_create_model in enumerate([create_model1, create_model2, create_model3, create_model4]):\n",
    "    weight_flag[i] = False\n",
    "    for activation_layers in params_grid['activation_layers']:\n",
    "        model = func_create_model(loss='categorical_crossentropy', activation_layers=activation_layers)\n",
    "        if not weight_flag[i]:\n",
    "            model.save_weights('model{}.h5'.format(i))\n",
    "            weight_flag[i] = True\n",
    "        else:\n",
    "            model.load_weights('model{}.h5'.format(i))\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=256, validation_split=0.2, verbose=0)\n",
    "\n",
    "        results = model.evaluate(X_test, y_test)\n",
    "        print('test loss, test acc:', results)\n",
    "\n",
    "        # model, loss, loss_err, acc\n",
    "        results_list.append([i + 1, activation_layers, results[0], results[1]])\n",
    "\n",
    "df_results = pd.DataFrame(results_list, columns=['model', 'activation_layers', 'loss_err', 'acc'])\n",
    "df_results.sort_values('acc', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f226553",
   "metadata": {},
   "source": [
    "Первая модель с любым слоем актвации вырвалась в победители. Но если попробовать объективно оценить, то лучшим выбором будет `elu`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781f7fb",
   "metadata": {},
   "source": [
    "Теперь подберём функцию активации на выходном слое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbcf320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4449 - accuracy: 0.8745\n",
      "test loss, test acc: [0.4448978006839752, 0.8744999766349792]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4460 - accuracy: 0.8756\n",
      "test loss, test acc: [0.446001797914505, 0.8755999803543091]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4692 - accuracy: 0.8820\n",
      "test loss, test acc: [0.46920403838157654, 0.8820000290870667]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4700 - accuracy: 0.8806\n",
      "test loss, test acc: [0.4699776768684387, 0.8805999755859375]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.5590 - accuracy: 0.8358\n",
      "test loss, test acc: [0.5589820146560669, 0.8357999920845032]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5668 - accuracy: 0.8329\n",
      "test loss, test acc: [0.5667523741722107, 0.8328999876976013]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5779 - accuracy: 0.8644\n",
      "test loss, test acc: [0.577915370464325, 0.8644000291824341]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5758 - accuracy: 0.8649\n",
      "test loss, test acc: [0.5757864713668823, 0.8648999929428101]\n",
      "CPU times: user 1min 23s, sys: 38.8 s, total: 2min 2s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>activation_last</th>\n",
       "      <th>loss_err</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.469204</td>\n",
       "      <td>0.8820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.469978</td>\n",
       "      <td>0.8806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.446002</td>\n",
       "      <td>0.8756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.444898</td>\n",
       "      <td>0.8745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.575786</td>\n",
       "      <td>0.8649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.577915</td>\n",
       "      <td>0.8644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.558982</td>\n",
       "      <td>0.8358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.566752</td>\n",
       "      <td>0.8329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model activation_last  loss_err     acc\n",
       "2      2            tanh  0.469204  0.8820\n",
       "3      2         sigmoid  0.469978  0.8806\n",
       "1      1         sigmoid  0.446002  0.8756\n",
       "0      1            tanh  0.444898  0.8745\n",
       "7      4         sigmoid  0.575786  0.8649\n",
       "6      4            tanh  0.577915  0.8644\n",
       "4      3            tanh  0.558982  0.8358\n",
       "5      3         sigmoid  0.566752  0.8329"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results_list = list()\n",
    "weight_flag = dict()\n",
    "\n",
    "for i, func_create_model in enumerate([create_model1, create_model2, create_model3, create_model4]):\n",
    "    weight_flag[i] = False\n",
    "    for activation_last in params_grid['activation_last']:\n",
    "        model = func_create_model(loss='categorical_crossentropy', activation_layers='elu', activation_last=activation_last)\n",
    "        if not weight_flag[i]:\n",
    "            model.save_weights('model{}.h5'.format(i))\n",
    "            weight_flag[i] = True\n",
    "        else:\n",
    "            model.load_weights('model{}.h5'.format(i))\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=256, validation_split=0.2, verbose=0)\n",
    "\n",
    "        results = model.evaluate(X_test, y_test)\n",
    "        print('test loss, test acc:', results)\n",
    "\n",
    "        # model, loss, loss_err, acc\n",
    "        results_list.append([i + 1, activation_last, results[0], results[1]])\n",
    "\n",
    "df_results = pd.DataFrame(results_list, columns=['model', 'activation_last', 'loss_err', 'acc'])\n",
    "df_results.sort_values('acc', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dab2a5",
   "metadata": {},
   "source": [
    "50/50. Очередной такой результат. Возьмём победителя из первой строки - 'tahn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38e4ff71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': [5, 10, 15],\n",
       " 'batch_size': [256, 512, 1024],\n",
       " 'loss': ['poisson', 'binary_crossentropy', 'categorical_crossentropy'],\n",
       " 'optimizer': ['SGD', 'RMSprop', 'Adam'],\n",
       " 'metrics': ['accuracy', 'binary_crossentropy', 'hinge'],\n",
       " 'activation_layers': ['relu', 'elu', 'selu'],\n",
       " 'activation_last': ['tanh', 'sigmoid']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839c358",
   "metadata": {},
   "source": [
    "Следующий параметр для анализа и подбора metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a4464ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4258 - accuracy: 0.8874\n",
      "test loss, test acc: [0.425801157951355, 0.8873999714851379]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4263 - binary_crossentropy: 0.9398\n",
      "test loss, test acc: [0.4262879490852356, 0.9398491382598877]\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4272 - hinge: 1.3310\n",
      "test loss, test acc: [0.42718321084976196, 1.33101224899292]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4575 - accuracy: 0.8844\n",
      "test loss, test acc: [0.45752832293510437, 0.8844000101089478]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4573 - binary_crossentropy: 0.8041\n",
      "test loss, test acc: [0.45733878016471863, 0.8041284680366516]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4574 - hinge: 1.3056\n",
      "test loss, test acc: [0.4574469327926636, 1.3056365251541138]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6615 - accuracy: 0.8134\n",
      "test loss, test acc: [0.6614805459976196, 0.8133999705314636]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6675 - binary_crossentropy: 1.0693\n",
      "test loss, test acc: [0.667487621307373, 1.0693175792694092]\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6686 - hinge: 1.3517\n",
      "test loss, test acc: [0.6686159372329712, 1.3517283201217651]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.5685 - accuracy: 0.8648\n",
      "test loss, test acc: [0.5684753060340881, 0.864799976348877]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5670 - binary_crossentropy: 0.6440\n",
      "test loss, test acc: [0.5670472383499146, 0.6439990401268005]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.5677 - hinge: 1.2761\n",
      "test loss, test acc: [0.5676729083061218, 1.2761213779449463]\n",
      "CPU times: user 2min 14s, sys: 1min 6s, total: 3min 20s\n",
      "Wall time: 2min 29s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metrics</th>\n",
       "      <th>loss_err</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.425801</td>\n",
       "      <td>0.887400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.426288</td>\n",
       "      <td>0.939849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.427183</td>\n",
       "      <td>1.331012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.457339</td>\n",
       "      <td>0.804128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>1.305637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.457528</td>\n",
       "      <td>0.884400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.567047</td>\n",
       "      <td>0.643999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.567673</td>\n",
       "      <td>1.276121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.568475</td>\n",
       "      <td>0.864800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.661481</td>\n",
       "      <td>0.813400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.667488</td>\n",
       "      <td>1.069318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.668616</td>\n",
       "      <td>1.351728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model              metrics  loss_err       acc\n",
       "0       1             accuracy  0.425801  0.887400\n",
       "1       1  binary_crossentropy  0.426288  0.939849\n",
       "2       1                hinge  0.427183  1.331012\n",
       "4       2  binary_crossentropy  0.457339  0.804128\n",
       "5       2                hinge  0.457447  1.305637\n",
       "3       2             accuracy  0.457528  0.884400\n",
       "10      4  binary_crossentropy  0.567047  0.643999\n",
       "11      4                hinge  0.567673  1.276121\n",
       "9       4             accuracy  0.568475  0.864800\n",
       "6       3             accuracy  0.661481  0.813400\n",
       "7       3  binary_crossentropy  0.667488  1.069318\n",
       "8       3                hinge  0.668616  1.351728"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results_list = list()\n",
    "weight_flag = dict()\n",
    "\n",
    "for i, func_create_model in enumerate([create_model1, create_model2, create_model3, create_model4]):\n",
    "    weight_flag[i] = False\n",
    "    for metrics in params_grid['metrics']:\n",
    "        model = func_create_model(loss='categorical_crossentropy', activation_layers='elu', activation_last='tahn', metrics=metrics)\n",
    "        if not weight_flag[i]:\n",
    "            model.save_weights('model{}.h5'.format(i))\n",
    "            weight_flag[i] = True\n",
    "        else:\n",
    "            model.load_weights('model{}.h5'.format(i))\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=256, validation_split=0.2, verbose=0)\n",
    "\n",
    "        results = model.evaluate(X_test, y_test)\n",
    "        print('test loss, test acc:', results)\n",
    "\n",
    "        # model, loss, loss_err, acc\n",
    "        results_list.append([i + 1, metrics, results[0], results[1]])\n",
    "\n",
    "df_results = pd.DataFrame(results_list, columns=['model', 'metrics', 'loss_err', 'acc'])\n",
    "df_results.sort_values('loss_err', axis=0, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54060013",
   "metadata": {},
   "source": [
    "Сложно оценивать метрики, т.к. они по разному считаются и где-то надо меньшую, а где-то большую. Очередной результат 50/50. Оставим `accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46d61f",
   "metadata": {},
   "source": [
    "Подберём `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdc4b9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4225 - accuracy: 0.8819\n",
      "test loss, test acc: [0.4225196838378906, 0.8819000124931335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 13:57:08.655433: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1435 - accuracy: 0.9557\n",
      "test loss, test acc: [0.14352935552597046, 0.9556999802589417]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1294 - accuracy: 0.9601\n",
      "test loss, test acc: [0.12938310205936432, 0.960099995136261]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4666 - accuracy: 0.8790\n",
      "test loss, test acc: [0.46662846207618713, 0.8790000081062317]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1328 - accuracy: 0.9616\n",
      "test loss, test acc: [0.13283106684684753, 0.9616000056266785]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1368 - accuracy: 0.9621\n",
      "test loss, test acc: [0.13678814470767975, 0.9621000289916992]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6243 - accuracy: 0.8286\n",
      "test loss, test acc: [0.6242768168449402, 0.8285999894142151]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1870 - accuracy: 0.9456\n",
      "test loss, test acc: [0.18695855140686035, 0.9455999732017517]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1639 - accuracy: 0.9518\n",
      "test loss, test acc: [0.16387152671813965, 0.9517999887466431]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6231 - accuracy: 0.8511\n",
      "test loss, test acc: [0.6230926513671875, 0.8511000275611877]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1419 - accuracy: 0.9570\n",
      "test loss, test acc: [0.14192576706409454, 0.9570000171661377]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1480 - accuracy: 0.9555\n",
      "test loss, test acc: [0.14803750813007355, 0.9555000066757202]\n",
      "CPU times: user 2min 8s, sys: 1min 1s, total: 3min 10s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>loss_err</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.9621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.132831</td>\n",
       "      <td>0.9616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.129383</td>\n",
       "      <td>0.9601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.141926</td>\n",
       "      <td>0.9570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.143529</td>\n",
       "      <td>0.9557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.148038</td>\n",
       "      <td>0.9555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.163872</td>\n",
       "      <td>0.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.186959</td>\n",
       "      <td>0.9456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.422520</td>\n",
       "      <td>0.8819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.466628</td>\n",
       "      <td>0.8790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.623093</td>\n",
       "      <td>0.8511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.624277</td>\n",
       "      <td>0.8286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model optimizer  loss_err     acc\n",
       "5       2      Adam  0.136788  0.9621\n",
       "4       2   RMSprop  0.132831  0.9616\n",
       "2       1      Adam  0.129383  0.9601\n",
       "10      4   RMSprop  0.141926  0.9570\n",
       "1       1   RMSprop  0.143529  0.9557\n",
       "11      4      Adam  0.148038  0.9555\n",
       "8       3      Adam  0.163872  0.9518\n",
       "7       3   RMSprop  0.186959  0.9456\n",
       "0       1       SGD  0.422520  0.8819\n",
       "3       2       SGD  0.466628  0.8790\n",
       "9       4       SGD  0.623093  0.8511\n",
       "6       3       SGD  0.624277  0.8286"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results_list = list()\n",
    "weight_flag = dict()\n",
    "\n",
    "for i, func_create_model in enumerate([create_model1, create_model2, create_model3, create_model4]):\n",
    "    weight_flag[i] = False\n",
    "    for optimizer in params_grid['optimizer']:\n",
    "        model = func_create_model(loss='categorical_crossentropy', activation_layers='elu', activation_last='tahn',\n",
    "                                  metrics='accuracy', optimizer=optimizer)\n",
    "        if not weight_flag[i]:\n",
    "            model.save_weights('model{}.h5'.format(i))\n",
    "            weight_flag[i] = True\n",
    "        else:\n",
    "            model.load_weights('model{}.h5'.format(i))\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=256, validation_split=0.2, verbose=0)\n",
    "\n",
    "        results = model.evaluate(X_test, y_test)\n",
    "        print('test loss, test acc:', results)\n",
    "\n",
    "        # model, loss, loss_err, acc\n",
    "        results_list.append([i + 1, optimizer, results[0], results[1]])\n",
    "\n",
    "df_results = pd.DataFrame(results_list, columns=['model', 'optimizer', 'loss_err', 'acc'])\n",
    "df_results.sort_values('acc', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03736e80",
   "metadata": {},
   "source": [
    "Если смотреть по каждой модели отдельно, то победил `Adam`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebebed30",
   "metadata": {},
   "source": [
    "Посмотрим, как количество эпох влияет на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a8b0959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1346 - accuracy: 0.9594\n",
      "test loss, test acc: [0.13457630574703217, 0.9593999981880188]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1145 - accuracy: 0.9644\n",
      "test loss, test acc: [0.11449124664068222, 0.9643999934196472]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0978 - accuracy: 0.9723\n",
      "test loss, test acc: [0.09778628498315811, 0.9722999930381775]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1340 - accuracy: 0.9608\n",
      "test loss, test acc: [0.13401663303375244, 0.9607999920845032]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0979 - accuracy: 0.9713\n",
      "test loss, test acc: [0.09793738275766373, 0.9713000059127808]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0843 - accuracy: 0.9742\n",
      "test loss, test acc: [0.08425764739513397, 0.9742000102996826]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1643 - accuracy: 0.9535\n",
      "test loss, test acc: [0.1642637401819229, 0.953499972820282]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1204 - accuracy: 0.9646\n",
      "test loss, test acc: [0.12044206261634827, 0.9646000266075134]\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1437 - accuracy: 0.9634\n",
      "test loss, test acc: [0.14366497099399567, 0.9634000062942505]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1587 - accuracy: 0.9518\n",
      "test loss, test acc: [0.15866373479366302, 0.9517999887466431]\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1150 - accuracy: 0.9667\n",
      "test loss, test acc: [0.11503078788518906, 0.96670001745224]\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1034 - accuracy: 0.9705\n",
      "test loss, test acc: [0.10338062793016434, 0.9704999923706055]\n",
      "CPU times: user 3min 42s, sys: 1min 45s, total: 5min 28s\n",
      "Wall time: 4min 19s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_err</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.084258</td>\n",
       "      <td>0.9742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.097786</td>\n",
       "      <td>0.9723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.097937</td>\n",
       "      <td>0.9713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.103381</td>\n",
       "      <td>0.9705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.9667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.120442</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.114491</td>\n",
       "      <td>0.9644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.143665</td>\n",
       "      <td>0.9634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.134017</td>\n",
       "      <td>0.9608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.9594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.164264</td>\n",
       "      <td>0.9535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.158664</td>\n",
       "      <td>0.9518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  epoch  loss_err     acc\n",
       "5       2     15  0.084258  0.9742\n",
       "2       1     15  0.097786  0.9723\n",
       "4       2     10  0.097937  0.9713\n",
       "11      4     15  0.103381  0.9705\n",
       "10      4     10  0.115031  0.9667\n",
       "7       3     10  0.120442  0.9646\n",
       "1       1     10  0.114491  0.9644\n",
       "8       3     15  0.143665  0.9634\n",
       "3       2      5  0.134017  0.9608\n",
       "0       1      5  0.134576  0.9594\n",
       "6       3      5  0.164264  0.9535\n",
       "9       4      5  0.158664  0.9518"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results_list = list()\n",
    "weight_flag = dict()\n",
    "\n",
    "for i, func_create_model in enumerate([create_model1, create_model2, create_model3, create_model4]):\n",
    "    weight_flag[i] = False\n",
    "    for epoch in params_grid['epochs']:\n",
    "        model = func_create_model(loss='categorical_crossentropy', activation_layers='elu', activation_last='tahn',\n",
    "                                  metrics='accuracy', optimizer='Adam')\n",
    "        if not weight_flag[i]:\n",
    "            model.save_weights('model{}.h5'.format(i))\n",
    "            weight_flag[i] = True\n",
    "        else:\n",
    "            model.load_weights('model{}.h5'.format(i))\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=epoch, batch_size=256, validation_split=0.2, verbose=0)\n",
    "\n",
    "        results = model.evaluate(X_test, y_test)\n",
    "        print('test loss, test acc:', results)\n",
    "\n",
    "        # model, loss, loss_err, acc\n",
    "        results_list.append([i + 1, epoch, results[0], results[1]])\n",
    "\n",
    "df_results = pd.DataFrame(results_list, columns=['model', 'epoch', 'loss_err', 'acc'])\n",
    "df_results.sort_values('acc', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff5cc6",
   "metadata": {},
   "source": [
    "15 эпох у трёх моделей победили. Значит при таком небольшом количестве эпох чем больше тем лучше. Это не значит, что не будет переобчения. Но похоже при таких цифрах можно сделать +5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a581ae2",
   "metadata": {},
   "source": [
    "Судя по результатам из последнего подбора (из предыдущих тоже, но не всех) какая бы глубокая сеть не была, она будет избыточной для решения данной задачи. Вторая модель с одним скрытым слоем и одним выходным, т.е. только два уровня обучаемых весов. И она ещё и победитель. На самом деле результаты не слишком разные, чтобы сказать, что именно такие параметры будут лучшими. Поэтому и хотелось сделать большое исследование с подбором параметров всех со всеми, но не вышло."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58363104",
   "metadata": {},
   "source": [
    "Итого: на точность модели может влиять любой из параметров (из больше чем в этой работе). В связи с чем надо делать короткий эксперимент и дальше дожимать данные и адаптировать модель. Слишком глубокая - не вседа хорошо."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
